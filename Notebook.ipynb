{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing regular package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision, os, copy\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 1000\n",
    "batch_size = 64\n",
    "LR = 0.0001\n",
    "\n",
    "dataset_folder = \"dataset\"\n",
    "\n",
    "noise_magnitude = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining transformation to adapt the feet dataset to the ImageNet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_tranform = transforms.Compose([\n",
    "    #Resizing the image\n",
    "    transforms.Resize(256),\n",
    "    #Center crop\n",
    "    transforms.CenterCrop(224),\n",
    "    #Adapting to torch tensor\n",
    "    transforms.ToTensor(),\n",
    "    #Normalizing to ImageNet\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "for param in pretrain_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the images and extracting the vector of extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019044548d2d4279a6bae6b76b2487ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_folder(folder):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for img_file in tqdm(os.listdir(folder)):\n",
    "        if(img_file[-4:] == \".jpg\"):\n",
    "            img = Image.open(folder+\"/\"+ img_file)\n",
    "            #feature extraction\n",
    "            k = normalization_tranform(img).view(-1, 3, 224, 224)\n",
    "            result = pretrain_model(k).view(-1)\n",
    "            #End of feature extraction\n",
    "            data.append(result)\n",
    "        else:#The xml file\n",
    "            label = np.zeros((2))\n",
    "            with open(folder+\"/\"+ img_file, \"r\") as fa:\n",
    "                v = fa.read().split(\"<name>\")[1].split(\"</name>\")[0]\n",
    "                if(v == \"Infection and Ischaemia\"):\n",
    "                    label[0] = 1\n",
    "                    label[1] = 1\n",
    "                elif(v == \"Infection\"):\n",
    "                    label[0] = 1\n",
    "                elif(v == \"Ischaemia\"):\n",
    "                    label[1] = 1\n",
    "            labels.append(torch.from_numpy(label))\n",
    "\n",
    "    label_tensor =  torch.stack(labels).view(-1, 2).float()\n",
    "    data_tensor = torch.stack(data)\n",
    "    return data_tensor, label_tensor\n",
    "\n",
    "\n",
    "x_train, y_train = load_folder(dataset_folder+\"/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174e1214c8974c72b096db81189fe557"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = load_folder(dataset_folder+\"/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(TensorDataset(x_train,y_train), batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the trainable part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Quantum network module.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Defining quantum layer structure\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        #Starting with a batch normalization\n",
    "        self.entry_norm = nn.BatchNorm1d(1000)\n",
    "        self.fc1 = nn.Linear(1000, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defining dataflow in the quantum layer\n",
    "        \"\"\"\n",
    "        \n",
    "        #normalizing data with the batch normalization\n",
    "        x = self.entry_norm(x)\n",
    "        #dimensionality reduction\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm1d-1                 [-1, 1000]           2,000\n",
      "            Linear-2                    [-1, 2]           2,002\n",
      "================================================================\n",
      "Total params: 4,002\n",
      "Trainable params: 4,002\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "basic_architecture = TrainableModel()\n",
    "summary(basic_architecture, input_size=(1000,), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_basic = optim.Adam(basic_architecture.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training done. Testing at 0%\n",
      "\tloss: 16.854551509022713 \n",
      "\tval_loss: 6.3851258754730225\n",
      "Epoch 2: Training done. Testing at 0%\n",
      "\tloss: 16.311848610639572 \n",
      "\tval_loss: 6.238152265548706\n",
      "Epoch 3: Training done. Testing at 0%\n",
      "\tloss: 16.067451290786266 \n",
      "\tval_loss: 6.11556601524353\n",
      "Epoch 4: Training done. Testing at 0%\n",
      "\tloss: 15.791720889508724 \n",
      "\tval_loss: 6.018547296524048\n",
      "Epoch 5: Training done. Testing at 0%\n",
      "\tloss: 15.543142326176167 \n",
      "\tval_loss: 5.938793778419495\n",
      "Epoch 6: Training done. Testing at 0%\n",
      "\tloss: 15.435065887868404 \n",
      "\tval_loss: 5.874841690063477\n",
      "Epoch 7: Training done. Testing at 0%\n",
      "\tloss: 15.161069460213184 \n",
      "\tval_loss: 5.8293696641922\n",
      "Epoch 8: Training done. Testing at 0%\n",
      "\tloss: 14.965751770883799 \n",
      "\tval_loss: 5.787895202636719\n",
      "Epoch 9: Training done. Testing at 0%\n",
      "\tloss: 14.845313247293234 \n",
      "\tval_loss: 5.75924026966095\n",
      "Epoch 10: Training done. Testing at 0%\n",
      "\tloss: 14.795842595398426 \n",
      "\tval_loss: 5.744205594062805\n",
      "Epoch 11: Training done. Testing at 0%\n",
      "\tloss: 14.582713320851326 \n",
      "\tval_loss: 5.720628619194031\n",
      "Epoch 12: Training done. Testing at 0%\n",
      "\tloss: 14.335584979504347 \n",
      "\tval_loss: 5.706522345542908\n",
      "Epoch 13: Training done. Testing at 0%\n",
      "\tloss: 14.301196679472923 \n",
      "\tval_loss: 5.691347122192383\n",
      "Epoch 14: Training done. Testing at 0%\n",
      "\tloss: 14.089689578860998 \n",
      "\tval_loss: 5.675833225250244\n",
      "Epoch 15: Training done. Testing at 0%\n",
      "\tloss: 13.991141729056835 \n",
      "\tval_loss: 5.654825806617737\n",
      "Epoch 16: Training done. Testing at 0%\n",
      "\tloss: 13.888023007661104 \n",
      "\tval_loss: 5.635212779045105\n",
      "Epoch 17: Training done. Testing at 0%\n",
      "\tloss: 13.75872527807951 \n",
      "\tval_loss: 5.61884880065918\n",
      "Epoch 18: Training done. Testing at 0%\n",
      "\tloss: 13.5776874050498 \n",
      "\tval_loss: 5.602358937263489\n",
      "Epoch 19: Training done. Testing at 0%\n",
      "\tloss: 13.462409399449825 \n",
      "\tval_loss: 5.589568734169006\n",
      "Epoch 20: Training done. Testing at 0%\n",
      "\tloss: 13.279608186334372 \n",
      "\tval_loss: 5.571163058280945\n",
      "Epoch 21: Training done. Testing at 0%\n",
      "\tloss: 13.14136216044426 \n",
      "\tval_loss: 5.556368350982666\n",
      "Epoch 22: Training done. Testing at 0%\n",
      "\tloss: 13.03261349722743 \n",
      "\tval_loss: 5.540854454040527\n",
      "Epoch 23: Training done. Testing at 0%\n",
      "\tloss: 12.960527390241623 \n",
      "\tval_loss: 5.51890504360199\n",
      "Epoch 24: Training done. Testing at 0%\n",
      "\tloss: 12.82654944434762 \n",
      "\tval_loss: 5.509620308876038\n",
      "Epoch 25: Training done. Testing at 0%\n",
      "\tloss: 12.717622336000204 \n",
      "\tval_loss: 5.492969512939453\n",
      "Epoch 26: Training done. Testing at 0%\n",
      "\tloss: 12.693332858383656 \n",
      "\tval_loss: 5.475255489349365\n",
      "Epoch 27: Training done. Testing at 0%\n",
      "\tloss: 12.586165931075811 \n",
      "\tval_loss: 5.467830061912537\n",
      "Epoch 28: Training done. Testing at 0%\n",
      "\tloss: 12.381024055182934 \n",
      "\tval_loss: 5.453364014625549\n",
      "Epoch 29: Training done. Testing at 0%\n",
      "\tloss: 12.404653877019882 \n",
      "\tval_loss: 5.430804133415222\n",
      "Epoch 30: Training done. Testing at 0%\n",
      "\tloss: 12.182424794882536 \n",
      "\tval_loss: 5.417908072471619\n",
      "Epoch 31: Training done. Testing at 0%\n",
      "\tloss: 12.113907404243946 \n",
      "\tval_loss: 5.398342251777649\n",
      "Epoch 32: Training done. Testing at 0%\n",
      "\tloss: 12.022737938910723 \n",
      "\tval_loss: 5.384584307670593\n",
      "Epoch 33: Training done. Testing at 0%\n",
      "\tloss: 11.859369955956936 \n",
      "\tval_loss: 5.37039577960968\n",
      "Epoch 34: Training done. Testing at 0%\n",
      "\tloss: 11.836869172751904 \n",
      "\tval_loss: 5.361242651939392\n",
      "Epoch 35: Training done. Testing at 0%\n",
      "\tloss: 11.781601704657078 \n",
      "\tval_loss: 5.352487564086914\n",
      "Epoch 36: Training done. Testing at 0%\n",
      "\tloss: 11.55481544137001 \n",
      "\tval_loss: 5.346398949623108\n",
      "Epoch 37: Training done. Testing at 0%\n",
      "\tloss: 11.634147625416517 \n",
      "\tval_loss: 5.335887908935547\n",
      "Epoch 38: Training done. Testing at 0%\n",
      "\tloss: 11.498899348080158 \n",
      "\tval_loss: 5.316010594367981\n",
      "Epoch 39: Training done. Testing at 0%\n",
      "\tloss: 11.253175105899572 \n",
      "\tval_loss: 5.3042861223220825\n",
      "Epoch 40: Training done. Testing at 0%\n",
      "\tloss: 11.36423547193408 \n",
      "\tval_loss: 5.295720219612122\n",
      "Epoch 41: Training done. Testing at 0%\n",
      "\tloss: 11.197062987834215 \n",
      "\tval_loss: 5.287320971488953\n",
      "Epoch 42: Training done. Testing at 0%\n",
      "\tloss: 11.205000501126051 \n",
      "\tval_loss: 5.281492710113525\n",
      "Epoch 43: Training done. Testing at 0%\n",
      "\tloss: 11.156882140785456 \n",
      "\tval_loss: 5.279216766357422\n",
      "Epoch 44: Training done. Testing at 0%\n",
      "\tloss: 10.945759318768978 \n",
      "\tval_loss: 5.266911506652832\n",
      "Epoch 45: Training done. Testing at 0%\n",
      "\tloss: 10.859765004366636 \n",
      "\tval_loss: 5.255918383598328\n",
      "Epoch 46: Training done. Testing at 0%\n",
      "\tloss: 10.932696677744389 \n",
      "\tval_loss: 5.2409480810165405\n",
      "Epoch 47: Training done. Testing at 0%\n",
      "\tloss: 10.781452689319849 \n",
      "\tval_loss: 5.230642318725586\n",
      "Epoch 48: Training done. Testing at 0%\n",
      "\tloss: 10.733506355434656 \n",
      "\tval_loss: 5.223662853240967\n",
      "Epoch 49: Training done. Testing at 0%\n",
      "\tloss: 10.699869956821203 \n",
      "\tval_loss: 5.216367602348328\n",
      "Epoch 50: Training done. Testing at 0%\n",
      "\tloss: 10.53539938852191 \n",
      "\tval_loss: 5.200327277183533\n",
      "Epoch 51: Training done. Testing at 0%\n",
      "\tloss: 10.417323779314756 \n",
      "\tval_loss: 5.197656154632568\n",
      "Epoch 52: Training done. Testing at 0%\n",
      "\tloss: 10.477085813879967 \n",
      "\tval_loss: 5.189266562461853\n",
      "Epoch 53: Training done. Testing at 0%\n",
      "\tloss: 10.323381416499615 \n",
      "\tval_loss: 5.191200613975525\n",
      "Epoch 54: Training done. Testing at 0%\n",
      "\tloss: 10.235087607055902 \n",
      "\tval_loss: 5.1821640729904175\n",
      "Epoch 55: Training done. Testing at 0%\n",
      "\tloss: 10.406575080007315 \n",
      "\tval_loss: 5.172672271728516\n",
      "Epoch 56: Training done. Testing at 0%\n",
      "\tloss: 10.083974681794643 \n",
      "\tval_loss: 5.160988926887512\n",
      "Epoch 57: Training done. Testing at 0%\n",
      "\tloss: 10.083919286727905 \n",
      "\tval_loss: 5.151072978973389\n",
      "Epoch 58: Training done. Testing at 0%\n",
      "\tloss: 9.98403476178646 \n",
      "\tval_loss: 5.1390334367752075\n",
      "Epoch 59: Training done. Testing at 0%\n",
      "\tloss: 9.88978249952197 \n",
      "\tval_loss: 5.134091019630432\n",
      "Epoch 60: Training done. Testing at 0%\n",
      "\tloss: 9.764290161430836 \n",
      "\tval_loss: 5.121460318565369\n",
      "Epoch 61: Training done. Testing at 0%\n",
      "\tloss: 9.734537228941917 \n",
      "\tval_loss: 5.113033175468445\n",
      "Epoch 62: Training done. Testing at 0%\n",
      "\tloss: 9.681035336107016 \n",
      "\tval_loss: 5.109152913093567\n",
      "Epoch 63: Training done. Testing at 0%\n",
      "\tloss: 9.779229510575533 \n",
      "\tval_loss: 5.103384375572205\n",
      "Epoch 64: Training done. Testing at 0%\n",
      "\tloss: 9.614995453506708 \n",
      "\tval_loss: 5.096770763397217\n",
      "Epoch 65: Training done. Testing at 0%\n",
      "\tloss: 9.575298316776752 \n",
      "\tval_loss: 5.086477160453796\n",
      "Epoch 66: Training done. Testing at 0%\n",
      "\tloss: 9.453510619699955 \n",
      "\tval_loss: 5.077665209770203\n",
      "Epoch 67: Training done. Testing at 0%\n",
      "\tloss: 9.473610199987888 \n",
      "\tval_loss: 5.0696715116500854\n",
      "Epoch 68: Training done. Testing at 0%\n",
      "\tloss: 9.333725579082966 \n",
      "\tval_loss: 5.067099094390869\n",
      "Epoch 69: Training done. Testing at 0%\n",
      "\tloss: 9.292844515293837 \n",
      "\tval_loss: 5.061743259429932\n",
      "Epoch 70: Training done. Testing at 0%\n",
      "\tloss: 9.303186979144812 \n",
      "\tval_loss: 5.057944893836975\n",
      "Epoch 71: Training done. Testing at 0%\n",
      "\tloss: 9.174351673573256 \n",
      "\tval_loss: 5.052586197853088\n",
      "Epoch 72: Training done. Testing at 0%\n",
      "\tloss: 9.117627289146185 \n",
      "\tval_loss: 5.055772304534912\n",
      "Epoch 73: Training done. Testing at 0%\n",
      "\tloss: 9.011594790965319 \n",
      "\tval_loss: 5.045535922050476\n",
      "Epoch 74: Training done. Testing at 0%\n",
      "\tloss: 9.036079067736864 \n",
      "\tval_loss: 5.042083740234375\n",
      "Epoch 75: Training done. Testing at 0%\n",
      "\tloss: 8.960057727992535 \n",
      "\tval_loss: 5.031401753425598\n",
      "Epoch 76: Training done. Testing at 0%\n",
      "\tloss: 8.783962320536375 \n",
      "\tval_loss: 5.025347113609314\n",
      "Epoch 77: Training done. Testing at 0%\n",
      "\tloss: 8.971668060868979 \n",
      "\tval_loss: 5.022025108337402\n",
      "Epoch 78: Training done. Testing at 0%\n",
      "\tloss: 8.923181753605604 \n",
      "\tval_loss: 5.019017815589905\n",
      "Epoch 79: Training done. Testing at 0%\n",
      "\tloss: 8.769174423068762 \n",
      "\tval_loss: 5.005023121833801\n",
      "Epoch 80: Training done. Testing at 0%\n",
      "\tloss: 8.767239104956388 \n",
      "\tval_loss: 4.9981759786605835\n",
      "Epoch 81: Training done. Testing at 0%\n",
      "\tloss: 8.633293852210045 \n",
      "\tval_loss: 4.992303371429443\n",
      "Epoch 82: Training done. Testing at 0%\n",
      "\tloss: 8.548992983996868 \n",
      "\tval_loss: 4.987894892692566\n",
      "Epoch 83: Training done. Testing at 0%\n",
      "\tloss: 8.574676470831037 \n",
      "\tval_loss: 4.992478251457214\n",
      "Epoch 84: Training done. Testing at 0%\n",
      "\tloss: 8.453854674473405 \n",
      "\tval_loss: 4.98637855052948\n",
      "Epoch 85: Training done. Testing at 0%\n",
      "\tloss: 8.53604882210493 \n",
      "\tval_loss: 4.9703049659729\n",
      "Epoch 86: Training done. Testing at 0%\n",
      "\tloss: 8.363602422177792 \n",
      "\tval_loss: 4.968764662742615\n",
      "Epoch 87: Training done. Testing at 0%\n",
      "\tloss: 8.412197712808847 \n",
      "\tval_loss: 4.9753804206848145\n",
      "Epoch 88: Training done. Testing at 0%\n",
      "\tloss: 8.31559931114316 \n",
      "\tval_loss: 4.972806930541992\n",
      "Epoch 89: Training done. Testing at 0%\n",
      "\tloss: 8.315313205122948 \n",
      "\tval_loss: 4.967745423316956\n",
      "Epoch 90: Training done. Testing at 0%\n",
      "\tloss: 8.271457966417074 \n",
      "\tval_loss: 4.966867446899414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Training done. Testing at 0%\n",
      "\tloss: 8.309256259351969 \n",
      "\tval_loss: 4.961037755012512\n",
      "Epoch 92: Training done. Testing at 0%\n",
      "\tloss: 8.230861559510231 \n",
      "\tval_loss: 4.9627121686935425\n",
      "Epoch 93: Training done. Testing at 0%\n",
      "\tloss: 8.071281356737018 \n",
      "\tval_loss: 4.958340167999268\n",
      "Epoch 94: Training done. Testing at 0%\n",
      "\tloss: 8.094154320657253 \n",
      "\tval_loss: 4.959512829780579\n",
      "Epoch 95: Training done. Testing at 0%\n",
      "\tloss: 8.079372385516763 \n",
      "\tval_loss: 4.953677773475647\n",
      "Epoch 96: Training done. Testing at 0%\n",
      "\tloss: 7.997257761657238 \n",
      "\tval_loss: 4.945677638053894\n",
      "Epoch 97: Training done. Testing at 0%\n",
      "\tloss: 8.05708822235465 \n",
      "\tval_loss: 4.937266945838928\n",
      "Epoch 98: Training done. Testing at 0%\n",
      "\tloss: 7.836331956088543 \n",
      "\tval_loss: 4.937699317932129\n",
      "Epoch 99: Training done. Testing at 0%\n",
      "\tloss: 7.907587122172117 \n",
      "\tval_loss: 4.94412624835968\n",
      "Epoch 100: Training done. Testing at 0%\n",
      "\tloss: 7.8059677835553885 \n",
      "\tval_loss: 4.940162658691406\n",
      "Epoch 101: Training done. Testing at 0%\n",
      "\tloss: 7.77771757915616 \n",
      "\tval_loss: 4.938395977020264\n",
      "Epoch 102: Training done. Testing at 0%\n",
      "\tloss: 7.910389402881265 \n",
      "\tval_loss: 4.942125678062439\n",
      "Epoch 103: Training done. Testing at 0%\n",
      "\tloss: 7.796306975185871 \n",
      "\tval_loss: 4.943169593811035\n",
      "Epoch 104: Training done. Testing at 0%\n",
      "\tloss: 7.571702942252159 \n",
      "\tval_loss: 4.940006375312805\n",
      "Epoch 105: Training done. Testing at 0%\n",
      "\tloss: 7.623662395402789 \n",
      "\tval_loss: 4.939338684082031\n",
      "Epoch 106: Training done. Testing at 0%\n",
      "\tloss: 7.516483908519149 \n",
      "\tval_loss: 4.933133482933044\n",
      "Epoch 107: Training done. Testing at 0%\n",
      "\tloss: 7.496646387502551 \n",
      "\tval_loss: 4.930751323699951\n",
      "Epoch 108: Training done. Testing at 0%\n",
      "\tloss: 7.531102145090699 \n",
      "\tval_loss: 4.924905896186829\n",
      "Epoch 109: Training done. Testing at 0%\n",
      "\tloss: 7.407487627118826 \n",
      "\tval_loss: 4.923109173774719\n",
      "Epoch 110: Training done. Testing at 0%\n",
      "\tloss: 7.412934431806207 \n",
      "\tval_loss: 4.919169902801514\n",
      "Epoch 111: Training done. Testing at 0%\n",
      "\tloss: 7.3867318741977215 \n",
      "\tval_loss: 4.914319396018982\n",
      "Epoch 112: Training done. Testing at 0%\n",
      "\tloss: 7.290101556107402 \n",
      "\tval_loss: 4.911823153495789\n",
      "Epoch 113: Training done. Testing at 0%\n",
      "\tloss: 7.408739583566785 \n",
      "\tval_loss: 4.909945964813232\n",
      "Epoch 114: Training done. Testing at 0%\n",
      "\tloss: 7.203277179971337 \n",
      "\tval_loss: 4.909531474113464\n",
      "Epoch 115: Training done. Testing at 0%\n",
      "\tloss: 7.141793003305793 \n",
      "\tval_loss: 4.905094027519226\n",
      "Epoch 116: Training done. Testing at 0%\n",
      "\tloss: 7.229719836264849 \n",
      "\tval_loss: 4.905417323112488\n",
      "Epoch 117: Training done. Testing at 0%\n",
      "\tloss: 7.30768876709044 \n",
      "\tval_loss: 4.9053826332092285\n",
      "Epoch 118: Training done. Testing at 0%\n",
      "\tloss: 7.0765148885548115 \n",
      "\tval_loss: 4.904338002204895\n",
      "Epoch 119: Training done. Testing at 0%\n",
      "\tloss: 7.168012551963329 \n",
      "\tval_loss: 4.904129862785339\n",
      "Epoch 120: Training done. Testing at 0%\n",
      "\tloss: 7.037278076633811 \n",
      "\tval_loss: 4.906615376472473\n",
      "Epoch 121: Training done. Testing at 0%\n",
      "\tloss: 7.069935316219926 \n",
      "\tval_loss: 4.90185821056366\n",
      "Epoch 122: Training done. Testing at 0%\n",
      "\tloss: 7.05765675380826 \n",
      "\tval_loss: 4.904249310493469\n",
      "Epoch 123: Training done. Testing at 0%\n",
      "\tloss: 6.960690379142761 \n",
      "\tval_loss: 4.906243801116943\n",
      "Epoch 124: Training done. Testing at 0%\n",
      "\tloss: 6.84998563118279 \n",
      "\tval_loss: 4.906819224357605\n",
      "Epoch 125: Training done. Testing at 0%\n",
      "\tloss: 6.875899994745851 \n",
      "\tval_loss: 4.9053415060043335\n",
      "Epoch 126: Training done. Testing at 0%\n",
      "\tloss: 6.930333131924272 \n",
      "\tval_loss: 4.905964493751526\n",
      "Epoch 127: Training done. Testing at 0%\n",
      "\tloss: 6.706167886033654 \n",
      "\tval_loss: 4.910912990570068\n",
      "Epoch 128: Training done. Testing at 0%\n",
      "\tloss: 6.819132700562477 \n",
      "\tval_loss: 4.91220760345459\n",
      "Epoch 129: Training done. Testing at 0%\n",
      "\tloss: 7.0022783149033785 \n",
      "\tval_loss: 4.915877938270569\n",
      "Epoch 130: Training done. Testing at 0%\n",
      "\tloss: 6.616936925798655 \n",
      "\tval_loss: 4.913450360298157\n",
      "Epoch 131: Training done. Testing at 0%\n",
      "\tloss: 6.893774069845676 \n",
      "\tval_loss: 4.908319473266602\n",
      "Epoch 132: Training done. Testing at 0%\n",
      "\tloss: 6.783387774601579 \n",
      "\tval_loss: 4.908115983009338\n",
      "Epoch 133: Training done. Testing at 0%\n",
      "\tloss: 6.766368458047509 \n",
      "\tval_loss: 4.898292660713196\n",
      "Epoch 134: Training done. Testing at 0%\n",
      "\tloss: 6.665445463731885 \n",
      "\tval_loss: 4.900054335594177\n",
      "Epoch 135: Training done. Testing at 0%\n",
      "\tloss: 6.531261809170246 \n",
      "\tval_loss: 4.9048744440078735\n",
      "Epoch 136: Training done. Testing at 0%\n",
      "\tloss: 6.627686368301511 \n",
      "\tval_loss: 4.905119776725769\n",
      "Epoch 137: Training done. Testing at 0%\n",
      "\tloss: 6.505071025341749 \n",
      "\tval_loss: 4.906920790672302\n",
      "Epoch 138: Training done. Testing at 0%\n",
      "\tloss: 6.399652658030391 \n",
      "\tval_loss: 4.9093934297561646\n",
      "Epoch 139: Training done. Testing at 0%\n",
      "\tloss: 6.34718644246459 \n",
      "\tval_loss: 4.909284710884094\n",
      "Epoch 140: Training done. Testing at 0%\n",
      "\tloss: 6.379046026617289 \n",
      "\tval_loss: 4.901842474937439\n",
      "Epoch 141: Training done. Testing at 0%\n",
      "\tloss: 6.402002062648535 \n",
      "\tval_loss: 4.907584547996521\n",
      "Epoch 142: Training done. Testing at 0%\n",
      "\tloss: 6.3840397745370865 \n",
      "\tval_loss: 4.9068299531936646\n",
      "Epoch 143: Training done. Testing at 0%\n",
      "\tloss: 6.225041879341006 \n",
      "\tval_loss: 4.914955973625183\n",
      "Epoch 144: Training done. Testing at 0%\n",
      "\tloss: 6.264376878738403 \n",
      "\tval_loss: 4.920201301574707\n",
      "Epoch 145: Training done. Testing at 0%\n",
      "\tloss: 6.3497670609503984 \n",
      "\tval_loss: 4.922129273414612\n",
      "Epoch 146: Training done. Testing at 0%\n",
      "\tloss: 6.286147627979517 \n",
      "\tval_loss: 4.921290993690491\n",
      "Epoch 147: Training done. Testing at 0%\n",
      "\tloss: 6.156600875779986 \n",
      "\tval_loss: 4.922158241271973\n",
      "Epoch 148: Training done. Testing at 0%\n",
      "\tloss: 6.174738686531782 \n",
      "\tval_loss: 4.922016263008118\n",
      "Epoch 149: Training done. Testing at 0%\n",
      "\tloss: 6.070084001868963 \n",
      "\tval_loss: 4.923275113105774\n",
      "Epoch 150: Training done. Testing at 0%\n",
      "\tloss: 6.168164275586605 \n",
      "\tval_loss: 4.924927353858948\n",
      "Epoch 151: Training done. Testing at 0%\n",
      "\tloss: 6.028113607317209 \n",
      "\tval_loss: 4.930597901344299\n",
      "Epoch 152: Training done. Testing at 0%\n",
      "\tloss: 6.116330565884709 \n",
      "\tval_loss: 4.930421948432922\n",
      "Epoch 153: Training done. Testing at 0%\n",
      "\tloss: 6.000985512509942 \n",
      "\tval_loss: 4.932570934295654\n",
      "Epoch 154: Training done. Testing at 0%\n",
      "\tloss: 6.019852766767144 \n",
      "\tval_loss: 4.92469596862793\n",
      "Epoch 155: Training done. Testing at 0%\n",
      "\tloss: 5.976816656067967 \n",
      "\tval_loss: 4.926538467407227\n",
      "Epoch 156: Training done. Testing at 0%\n",
      "\tloss: 5.91615872643888 \n",
      "\tval_loss: 4.929476380348206\n",
      "Epoch 157: Training done. Testing at 0%\n",
      "\tloss: 5.932741828262806 \n",
      "\tval_loss: 4.9368284940719604\n",
      "Epoch 158: Training done. Testing at 0%\n",
      "\tloss: 5.904565880075097 \n",
      "\tval_loss: 4.942842364311218\n",
      "Epoch 159: Training done. Testing at 0%\n",
      "\tloss: 5.882611233741045 \n",
      "\tval_loss: 4.947113871574402\n",
      "Epoch 160: Training done. Testing at 0%\n",
      "\tloss: 5.976545747369528 \n",
      "\tval_loss: 4.943258285522461\n",
      "Epoch 161: Training done. Testing at 0%\n",
      "\tloss: 6.1298936530947685 \n",
      "\tval_loss: 4.943149566650391\n",
      "Epoch 162: Training done. Testing at 0%\n",
      "\tloss: 5.756968416273594 \n",
      "\tval_loss: 4.942785859107971\n",
      "Epoch 163: Training done. Testing at 0%\n",
      "\tloss: 5.867301138117909 \n",
      "\tval_loss: 4.948976039886475\n",
      "Epoch 164: Training done. Testing at 0%\n",
      "\tloss: 5.806156182661653 \n",
      "\tval_loss: 4.945096492767334\n",
      "Epoch 165: Training done. Testing at 0%\n",
      "\tloss: 6.053963642567396 \n",
      "\tval_loss: 4.947500109672546\n",
      "Epoch 166: Training done. Testing at 0%\n",
      "\tloss: 5.644049668684602 \n",
      "\tval_loss: 4.945335388183594\n",
      "Epoch 167: Training done. Testing at 0%\n",
      "\tloss: 5.712515180930495 \n",
      "\tval_loss: 4.946528434753418\n",
      "Epoch 168: Training done. Testing at 0%\n",
      "\tloss: 5.72000247426331 \n",
      "\tval_loss: 4.943757176399231\n",
      "Epoch 169: Training done. Testing at 0%\n",
      "\tloss: 5.839913975447416 \n",
      "\tval_loss: 4.947627425193787\n",
      "Epoch 170: Training done. Testing at 0%\n",
      "\tloss: 5.5471592377871275 \n",
      "\tval_loss: 4.953123450279236\n",
      "Epoch 171: Training done. Testing at 0%\n",
      "\tloss: 5.594623081386089 \n",
      "\tval_loss: 4.960985541343689\n",
      "Epoch 172: Training done. Testing at 0%\n",
      "\tloss: 5.6113133653998375 \n",
      "\tval_loss: 4.961028456687927\n",
      "Epoch 173: Training done. Testing at 0%\n",
      "\tloss: 5.571618236601353 \n",
      "\tval_loss: 4.961544513702393\n",
      "Epoch 174: Training done. Testing at 0%\n",
      "\tloss: 5.4894277472049 \n",
      "\tval_loss: 4.971185803413391\n",
      "Epoch 175: Training done. Testing at 0%\n",
      "\tloss: 5.610735442489386 \n",
      "\tval_loss: 4.976493000984192\n",
      "Epoch 176: Training done. Testing at 0%\n",
      "\tloss: 5.626034010201693 \n",
      "\tval_loss: 4.979605078697205\n",
      "Epoch 177: Training done. Testing at 0%\n",
      "\tloss: 5.455747954547405 \n",
      "\tval_loss: 4.976186156272888\n",
      "Epoch 178: Training done. Testing at 0%\n",
      "\tloss: 5.660826632753015 \n",
      "\tval_loss: 4.979064345359802\n",
      "Epoch 179: Training done. Testing at 0%\n",
      "\tloss: 5.381277218461037 \n",
      "\tval_loss: 4.985395431518555\n",
      "Epoch 180: Training done. Testing at 0%\n",
      "\tloss: 5.334236713126302 \n",
      "\tval_loss: 4.986286997795105\n",
      "Epoch 181: Training done. Testing at 0%\n",
      "\tloss: 5.607535030692816 \n",
      "\tval_loss: 4.982413172721863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182: Training done. Testing at 0%\n",
      "\tloss: 5.328463055193424 \n",
      "\tval_loss: 4.977174282073975\n",
      "Epoch 183: Training done. Testing at 0%\n",
      "\tloss: 5.223000422120094 \n",
      "\tval_loss: 4.979264259338379\n",
      "Epoch 184: Training done. Testing at 0%\n",
      "\tloss: 5.3123001717031 \n",
      "\tval_loss: 4.9836273193359375\n",
      "Epoch 185: Training done. Testing at 0%\n",
      "\tloss: 5.190187677741051 \n",
      "\tval_loss: 4.988788962364197\n",
      "Epoch 186: Training done. Testing at 0%\n",
      "\tloss: 5.190134858712554 \n",
      "\tval_loss: 4.995722651481628\n",
      "Epoch 187: Training done. Testing at 0%\n",
      "\tloss: 5.244546256959438 \n",
      "\tval_loss: 5.001248002052307\n",
      "Epoch 188: Training done. Testing at 0%\n",
      "\tloss: 5.3476043455302715 \n",
      "\tval_loss: 5.011087775230408\n",
      "Epoch 189: Training done. Testing at 0%\n",
      "\tloss: 5.18385854549706 \n",
      "\tval_loss: 5.0179338455200195\n",
      "Epoch 190: Training done. Testing at 0%\n",
      "\tloss: 5.139300737529993 \n",
      "\tval_loss: 5.020036697387695\n",
      "Epoch 191: Training done. Testing at 0%\n",
      "\tloss: 5.234853006899357 \n",
      "\tval_loss: 5.024714827537537\n",
      "Epoch 192: Training done. Testing at 0%\n",
      "\tloss: 5.169756226241589 \n",
      "\tval_loss: 5.024224162101746\n",
      "Epoch 193: Training done. Testing at 0%\n",
      "\tloss: 5.0533693470060825 \n",
      "\tval_loss: 5.0151543617248535\n",
      "Epoch 194: Training done. Testing at 0%\n",
      "\tloss: 5.087164338678122 \n",
      "\tval_loss: 5.011241555213928\n",
      "Epoch 195: Training done. Testing at 0%\n",
      "\tloss: 5.20392975024879 \n",
      "\tval_loss: 5.015666127204895\n",
      "Epoch 196: Training done. Testing at 0%\n",
      "\tloss: 5.21311404556036 \n",
      "\tval_loss: 5.027222514152527\n",
      "Epoch 197: Training done. Testing at 0%\n",
      "\tloss: 5.046527234837413 \n",
      "\tval_loss: 5.026296257972717\n",
      "Epoch 198: Training done. Testing at 0%\n",
      "\tloss: 5.072141984477639 \n",
      "\tval_loss: 5.035584568977356\n",
      "Epoch 199: Training done. Testing at 0%\n",
      "\tloss: 4.945583272725344 \n",
      "\tval_loss: 5.034990906715393\n",
      "Epoch 200: Training done. Testing at 0%\n",
      "\tloss: 5.088577400892973 \n",
      "\tval_loss: 5.034234881401062\n",
      "Epoch 201: Training done. Testing at 0%\n",
      "\tloss: 4.947775302454829 \n",
      "\tval_loss: 5.046305179595947\n",
      "Epoch 202: Training done. Testing at 0%\n",
      "\tloss: 4.961676033213735 \n",
      "\tval_loss: 5.049557089805603\n",
      "Epoch 203: Training done. Testing at 0%\n",
      "\tloss: 4.9438877031207085 \n",
      "\tval_loss: 5.051619529724121\n",
      "Epoch 204: Training done. Testing at 0%\n",
      "\tloss: 4.949917959049344 \n",
      "\tval_loss: 5.056422114372253\n",
      "Epoch 205: Training done. Testing at 0%\n",
      "\tloss: 5.09298100695014 \n",
      "\tval_loss: 5.061024069786072\n",
      "Epoch 206: Training done. Testing at 0%\n",
      "\tloss: 4.93035377189517 \n",
      "\tval_loss: 5.0561381578445435\n",
      "Epoch 207: Training done. Testing at 0%\n",
      "\tloss: 4.789733503013849 \n",
      "\tval_loss: 5.059846758842468\n",
      "Epoch 208: Training done. Testing at 0%\n",
      "\tloss: 4.912731586024165 \n",
      "\tval_loss: 5.061911702156067\n",
      "Epoch 209: Training done. Testing at 0%\n",
      "\tloss: 4.792221577838063 \n",
      "\tval_loss: 5.071320533752441\n",
      "Epoch 210: Training done. Testing at 0%\n",
      "\tloss: 5.075485935434699 \n",
      "\tval_loss: 5.070201873779297\n",
      "Epoch 211: Training done. Testing at 0%\n",
      "\tloss: 4.781468391418457 \n",
      "\tval_loss: 5.0684884786605835\n",
      "Epoch 212: Training done. Testing at 0%\n",
      "\tloss: 4.683337541297078 \n",
      "\tval_loss: 5.0737152099609375\n",
      "Epoch 213: Training done. Testing at 0%\n",
      "\tloss: 4.763733809813857 \n",
      "\tval_loss: 5.069064259529114\n",
      "Epoch 214: Training done. Testing at 0%\n",
      "\tloss: 4.882611345499754 \n",
      "\tval_loss: 5.0734992027282715\n",
      "Epoch 215: Training done. Testing at 0%\n",
      "\tloss: 4.735632574185729 \n",
      "\tval_loss: 5.0785088539123535\n",
      "Epoch 216: Training done. Testing at 0%\n",
      "\tloss: 4.714080588892102 \n",
      "\tval_loss: 5.086483597755432\n",
      "Epoch 217: Training done. Testing at 0%\n",
      "\tloss: 4.7514438778162 \n",
      "\tval_loss: 5.084014892578125\n",
      "Epoch 218: Training done. Testing at 0%\n",
      "\tloss: 4.6463956739753485 \n",
      "\tval_loss: 5.0853413343429565\n",
      "Epoch 219: Training done. Testing at 0%\n",
      "\tloss: 4.5930406507104635 \n",
      "\tval_loss: 5.094178676605225\n",
      "Epoch 220: Training done. Testing at 0%\n",
      "\tloss: 4.58254948630929 \n",
      "\tval_loss: 5.09816586971283\n",
      "Epoch 221: Training done. Testing at 0%\n",
      "\tloss: 4.634923005476594 \n",
      "\tval_loss: 5.096830487251282\n",
      "Epoch 222: Training done. Testing at 0%\n",
      "\tloss: 4.62570621073246 \n",
      "\tval_loss: 5.0967206954956055\n",
      "Epoch 223: Training done. Testing at 0%\n",
      "\tloss: 4.562656417489052 \n",
      "\tval_loss: 5.104700446128845\n",
      "Epoch 224: Training done. Testing at 0%\n",
      "\tloss: 4.7693939581513405 \n",
      "\tval_loss: 5.109980463981628\n",
      "Epoch 225: Training done. Testing at 0%\n",
      "\tloss: 4.604131827130914 \n",
      "\tval_loss: 5.119588851928711\n",
      "Epoch 226: Training done. Testing at 0%\n",
      "\tloss: 4.610717982053757 \n",
      "\tval_loss: 5.125255107879639\n",
      "Epoch 227: Training done. Testing at 0%\n",
      "\tloss: 4.539668088778853 \n",
      "\tval_loss: 5.128350377082825\n",
      "Epoch 228: Training done. Testing at 0%\n",
      "\tloss: 4.563759217038751 \n",
      "\tval_loss: 5.133719086647034\n",
      "Epoch 229: Training done. Testing at 0%\n",
      "\tloss: 4.714320143684745 \n",
      "\tval_loss: 5.133600354194641\n",
      "Epoch 230: Training done. Testing at 0%\n",
      "\tloss: 4.567085517570376 \n",
      "\tval_loss: 5.135226845741272\n",
      "Epoch 231: Training done. Testing at 0%\n",
      "\tloss: 4.455191967077553 \n",
      "\tval_loss: 5.134852409362793\n",
      "Epoch 232: Training done. Testing at 0%\n",
      "\tloss: 4.566673591732979 \n",
      "\tval_loss: 5.133380770683289\n",
      "Epoch 233: Training done. Testing at 0%\n",
      "\tloss: 4.451903321780264 \n",
      "\tval_loss: 5.138973355293274\n",
      "Epoch 234: Training done. Testing at 0%\n",
      "\tloss: 4.607393397018313 \n",
      "\tval_loss: 5.148936867713928\n",
      "Epoch 235: Training done. Testing at 0%\n",
      "\tloss: 4.336379470303655 \n",
      "\tval_loss: 5.154833436012268\n",
      "Epoch 236: Training done. Testing at 0%\n",
      "\tloss: 4.293329009786248 \n",
      "\tval_loss: 5.151060461997986\n",
      "Epoch 237: Training done. Testing at 0%\n",
      "\tloss: 4.246818404644728 \n",
      "\tval_loss: 5.1591421365737915\n",
      "Epoch 238: Training done. Testing at 0%\n",
      "\tloss: 4.225381918251514 \n",
      "\tval_loss: 5.163765907287598\n",
      "Epoch 239: Training done. Testing at 0%\n",
      "\tloss: 4.375638509169221 \n",
      "\tval_loss: 5.165735363960266\n",
      "Epoch 240: Training done. Testing at 0%\n",
      "\tloss: 4.296737963333726 \n",
      "\tval_loss: 5.1689382791519165\n",
      "Epoch 241: Training done. Testing at 0%\n",
      "\tloss: 4.3551892247051 \n",
      "\tval_loss: 5.175424575805664\n",
      "Epoch 242: Training done. Testing at 0%\n",
      "\tloss: 4.307097461074591 \n",
      "\tval_loss: 5.1816147565841675\n",
      "Epoch 243: Training done. Testing at 0%\n",
      "\tloss: 4.291881216689944 \n",
      "\tval_loss: 5.178984045982361\n",
      "Epoch 244: Training done. Testing at 0%\n",
      "\tloss: 4.205355268903077 \n",
      "\tval_loss: 5.17896831035614\n",
      "Epoch 245: Training done. Testing at 0%\n",
      "\tloss: 4.405369735322893 \n",
      "\tval_loss: 5.181619048118591\n",
      "Epoch 246: Training done. Testing at 0%\n",
      "\tloss: 4.321379290893674 \n",
      "\tval_loss: 5.176146984100342\n",
      "Epoch 247: Training done. Testing at 0%\n",
      "\tloss: 4.4553218353539705 \n",
      "\tval_loss: 5.186616897583008\n",
      "Epoch 248: Training done. Testing at 0%\n",
      "\tloss: 4.295719757676125 \n",
      "\tval_loss: 5.197372913360596\n",
      "Epoch 249: Training done. Testing at 0%\n",
      "\tloss: 4.1208629962056875 \n",
      "\tval_loss: 5.206332564353943\n",
      "Epoch 250: Training done. Testing at 0%\n",
      "\tloss: 4.160830221138895 \n",
      "\tval_loss: 5.206708073616028\n",
      "Epoch 251: Training done. Testing at 0%\n",
      "\tloss: 4.167803378775716 \n",
      "\tval_loss: 5.2083563804626465\n",
      "Epoch 252: Training done. Testing at 0%\n",
      "\tloss: 4.07403642963618 \n",
      "\tval_loss: 5.20810604095459\n",
      "Epoch 253: Training done. Testing at 0%\n",
      "\tloss: 4.047945054247975 \n",
      "\tval_loss: 5.208017706871033\n",
      "Epoch 254: Training done. Testing at 0%\n",
      "\tloss: 4.299718160182238 \n",
      "\tval_loss: 5.215624809265137\n",
      "Epoch 255: Training done. Testing at 0%\n",
      "\tloss: 4.131326578557491 \n",
      "\tval_loss: 5.220132350921631\n",
      "Epoch 256: Training done. Testing at 0%\n",
      "\tloss: 4.1455471478402615 \n",
      "\tval_loss: 5.225431323051453\n",
      "Epoch 257: Training done. Testing at 0%\n",
      "\tloss: 4.017518302425742 \n",
      "\tval_loss: 5.225645184516907\n",
      "Epoch 258: Training done. Testing at 0%\n",
      "\tloss: 4.044914323836565 \n",
      "\tval_loss: 5.2283631563186646\n",
      "Epoch 259: Training done. Testing at 0%\n",
      "\tloss: 4.09158506244421 \n",
      "\tval_loss: 5.22831916809082\n",
      "Epoch 260: Training done. Testing at 0%\n",
      "\tloss: 3.961506181396544 \n",
      "\tval_loss: 5.226261019706726\n",
      "Epoch 261: Training done. Testing at 0%\n",
      "\tloss: 4.141899501904845 \n",
      "\tval_loss: 5.224788665771484\n",
      "Epoch 262: Training done. Testing at 0%\n",
      "\tloss: 4.152392936870456 \n",
      "\tval_loss: 5.234217524528503\n",
      "Epoch 263: Training done. Testing at 0%\n",
      "\tloss: 4.113358959555626 \n",
      "\tval_loss: 5.243292689323425\n",
      "Epoch 264: Training done. Testing at 0%\n",
      "\tloss: 4.044687058776617 \n",
      "\tval_loss: 5.2461079359054565\n",
      "Epoch 265: Training done. Testing at 0%\n",
      "\tloss: 3.9686570521444082 \n",
      "\tval_loss: 5.251240253448486\n",
      "Epoch 266: Training done. Testing at 0%\n",
      "\tloss: 3.9372005108743906 \n",
      "\tval_loss: 5.2584428787231445\n",
      "Epoch 267: Training done. Testing at 0%\n",
      "\tloss: 3.9494298826903105 \n",
      "\tval_loss: 5.2673832178115845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268: Training done. Testing at 0%\n",
      "\tloss: 3.9438704205676913 \n",
      "\tval_loss: 5.268268704414368\n",
      "Epoch 269: Training done. Testing at 0%\n",
      "\tloss: 3.9459185684099793 \n",
      "\tval_loss: 5.266956210136414\n",
      "Epoch 270: Training done. Testing at 0%\n",
      "\tloss: 3.894252013415098 \n",
      "\tval_loss: 5.264816164970398\n",
      "Epoch 271: Training done. Testing at 0%\n",
      "\tloss: 3.819735251367092 \n",
      "\tval_loss: 5.267039895057678\n",
      "Epoch 272: Training done. Testing at 0%\n",
      "\tloss: 3.7805637307465076 \n",
      "\tval_loss: 5.269702792167664\n",
      "Epoch 273: Training done. Testing at 0%\n",
      "\tloss: 3.9220241978764534 \n",
      "\tval_loss: 5.2717612981796265\n",
      "Epoch 274: Training done. Testing at 0%\n",
      "\tloss: 3.813760492950678 \n",
      "\tval_loss: 5.273829102516174\n",
      "Epoch 275: Training done. Testing at 0%\n",
      "\tloss: 3.777075990103185 \n",
      "\tval_loss: 5.273447155952454\n",
      "Epoch 276: Training done. Testing at 0%\n",
      "\tloss: 3.828993615694344 \n",
      "\tval_loss: 5.278274416923523\n",
      "Epoch 277: Training done. Testing at 0%\n",
      "\tloss: 3.826278105378151 \n",
      "\tval_loss: 5.289437770843506\n",
      "Epoch 278: Training done. Testing at 0%\n",
      "\tloss: 3.8599679190665483 \n",
      "\tval_loss: 5.2990275621414185\n",
      "Epoch 279: Training done. Testing at 0%\n",
      "\tloss: 3.6759910425171256 \n",
      "\tval_loss: 5.297457218170166\n",
      "Epoch 280: Training done. Testing at 0%\n",
      "\tloss: 3.7130024628713727 \n",
      "\tval_loss: 5.307534098625183\n",
      "Epoch 281: Training done. Testing at 0%\n",
      "\tloss: 3.7687734747305512 \n",
      "\tval_loss: 5.310959815979004\n",
      "Epoch 282: Training done. Testing at 0%\n",
      "\tloss: 3.713043686002493 \n",
      "\tval_loss: 5.309573650360107\n",
      "Epoch 283: Training done. Testing at 0%\n",
      "\tloss: 3.6880600107833743 \n",
      "\tval_loss: 5.311218738555908\n",
      "Epoch 284: Training done. Testing at 0%\n",
      "\tloss: 3.7403871212154627 \n",
      "\tval_loss: 5.315598964691162\n",
      "Epoch 285: Training done. Testing at 0%\n",
      "\tloss: 3.706100388430059 \n",
      "\tval_loss: 5.320291042327881\n",
      "Epoch 286: Training done. Testing at 0%\n",
      "\tloss: 3.798185609281063 \n",
      "\tval_loss: 5.3272504806518555\n",
      "Epoch 287: Training done. Testing at 0%\n",
      "\tloss: 3.6558045288547873 \n",
      "\tval_loss: 5.328473925590515\n",
      "Epoch 288: Training done. Testing at 0%\n",
      "\tloss: 3.6535859275609255 \n",
      "\tval_loss: 5.339261054992676\n",
      "Epoch 289: Training done. Testing at 0%\n",
      "\tloss: 3.6430917754769325 \n",
      "\tval_loss: 5.335898280143738\n",
      "Epoch 290: Training done. Testing at 0%\n",
      "\tloss: 3.6006142208352685 \n",
      "\tval_loss: 5.337003707885742\n",
      "Epoch 291: Training done. Testing at 0%\n",
      "\tloss: 3.8734995163977146 \n",
      "\tval_loss: 5.343326568603516\n",
      "Epoch 292: Training done. Testing at 0%\n",
      "\tloss: 3.6748731089755893 \n",
      "\tval_loss: 5.339158415794373\n",
      "Epoch 293: Training done. Testing at 0%\n",
      "\tloss: 3.5281668370589614 \n",
      "\tval_loss: 5.344107270240784\n",
      "Epoch 294: Training done. Testing at 0%\n",
      "\tloss: 3.5710660787299275 \n",
      "\tval_loss: 5.348373770713806\n",
      "Epoch 295: Training done. Testing at 0%\n",
      "\tloss: 3.6980336643755436 \n",
      "\tval_loss: 5.352456092834473\n",
      "Epoch 296: Training done. Testing at 0%\n",
      "\tloss: 3.484203995205462 \n",
      "\tval_loss: 5.353593349456787\n",
      "Epoch 297: Training done. Testing at 0%\n",
      "\tloss: 3.5357807632535696 \n",
      "\tval_loss: 5.356394648551941\n",
      "Epoch 298: Training done. Testing at 0%\n",
      "\tloss: 3.813550140708685 \n",
      "\tval_loss: 5.3592106103897095\n",
      "Epoch 299: Training done. Testing at 0%\n",
      "\tloss: 3.5585343381389976 \n",
      "\tval_loss: 5.35964298248291\n",
      "Epoch 300: Training done. Testing at 0%\n",
      "\tloss: 3.700144885107875 \n",
      "\tval_loss: 5.368054032325745\n",
      "Epoch 301: Training done. Testing at 0%\n",
      "\tloss: 3.559889911673963 \n",
      "\tval_loss: 5.365144729614258\n",
      "Epoch 302: Training done. Testing at 0%\n",
      "\tloss: 3.538432724773884 \n",
      "\tval_loss: 5.371485114097595\n",
      "Epoch 303: Training done. Testing at 0%\n",
      "\tloss: 3.5160433212295175 \n",
      "\tval_loss: 5.375069260597229\n",
      "Epoch 304: Training done. Testing at 0%\n",
      "\tloss: 3.5753979235887527 \n",
      "\tval_loss: 5.382259368896484\n",
      "Epoch 305: Training done. Testing at 0%\n",
      "\tloss: 3.514047022908926 \n",
      "\tval_loss: 5.389660477638245\n",
      "Epoch 306: Training done. Testing at 0%\n",
      "\tloss: 3.3768514916300774 \n",
      "\tval_loss: 5.394690155982971\n",
      "Epoch 307: Training done. Testing at 0%\n",
      "\tloss: 3.5565317450091243 \n",
      "\tval_loss: 5.389729142189026\n",
      "Epoch 308: Training done. Testing at 0%\n",
      "\tloss: 3.385887616313994 \n",
      "\tval_loss: 5.393147349357605\n",
      "Epoch 309: Training done. Testing at 0%\n",
      "\tloss: 3.504805216565728 \n",
      "\tval_loss: 5.398478150367737\n",
      "Epoch 310: Training done. Testing at 0%\n",
      "\tloss: 3.5686814272776246 \n",
      "\tval_loss: 5.395284175872803\n",
      "Epoch 311: Training done. Testing at 0%\n",
      "\tloss: 3.367475997656584 \n",
      "\tval_loss: 5.403527855873108\n",
      "Epoch 312: Training done. Testing at 0%\n",
      "\tloss: 3.4716720459982753 \n",
      "\tval_loss: 5.406928896903992\n",
      "Epoch 313: Training done. Testing at 0%\n",
      "\tloss: 3.4549772860482335 \n",
      "\tval_loss: 5.412044048309326\n",
      "Epoch 314: Training done. Testing at 0%\n",
      "\tloss: 3.323502069339156 \n",
      "\tval_loss: 5.4123945236206055\n",
      "Epoch 315: Training done. Testing at 0%\n",
      "\tloss: 3.4035578332841396 \n",
      "\tval_loss: 5.412513613700867\n",
      "Epoch 316: Training done. Testing at 0%\n",
      "\tloss: 3.4251435082405806 \n",
      "\tval_loss: 5.416092753410339\n",
      "Epoch 317: Training done. Testing at 0%\n",
      "\tloss: 3.3168495232239366 \n",
      "\tval_loss: 5.424799919128418\n",
      "Epoch 318: Training done. Testing at 0%\n",
      "\tloss: 3.3104506824165583 \n",
      "\tval_loss: 5.42669141292572\n",
      "Epoch 319: Training done. Testing at 0%\n",
      "\tloss: 3.3503103740513325 \n",
      "\tval_loss: 5.4300312995910645\n",
      "Epoch 320: Training done. Testing at 0%\n",
      "\tloss: 3.3610882237553596 \n",
      "\tval_loss: 5.433313965797424\n",
      "Epoch 321: Training done. Testing at 0%\n",
      "\tloss: 3.4320047590881586 \n",
      "\tval_loss: 5.438229560852051\n",
      "Epoch 322: Training done. Testing at 0%\n",
      "\tloss: 3.313495426438749 \n",
      "\tval_loss: 5.4430543184280396\n",
      "Epoch 323: Training done. Testing at 0%\n",
      "\tloss: 3.2606379128992558 \n",
      "\tval_loss: 5.442193150520325\n",
      "Epoch 324: Training done. Testing at 0%\n",
      "\tloss: 3.300170049071312 \n",
      "\tval_loss: 5.450626730918884\n",
      "Epoch 325: Training done. Testing at 0%\n",
      "\tloss: 3.1834479039534926 \n",
      "\tval_loss: 5.4459357261657715\n",
      "Epoch 326: Training done. Testing at 0%\n",
      "\tloss: 3.313079004175961 \n",
      "\tval_loss: 5.452013969421387\n",
      "Epoch 327: Training done. Testing at 0%\n",
      "\tloss: 3.2971936780959368 \n",
      "\tval_loss: 5.4518723487854\n",
      "Epoch 328: Training done. Testing at 0%\n",
      "\tloss: 3.2076578363776207 \n",
      "\tval_loss: 5.453004240989685\n",
      "Epoch 329: Training done. Testing at 0%\n",
      "\tloss: 3.142204787582159 \n",
      "\tval_loss: 5.457168102264404\n",
      "Epoch 330: Training done. Testing at 0%\n",
      "\tloss: 3.203476366586983 \n",
      "\tval_loss: 5.467368721961975\n",
      "Epoch 331: Training done. Testing at 0%\n",
      "\tloss: 3.449106584303081 \n",
      "\tval_loss: 5.464129328727722\n",
      "Epoch 332: Training done. Testing at 0%\n",
      "\tloss: 3.1779952365905046 \n",
      "\tval_loss: 5.469262003898621\n",
      "Epoch 333: Training done. Testing at 0%\n",
      "\tloss: 3.260673701763153 \n",
      "\tval_loss: 5.475744724273682\n",
      "Epoch 334: Training done. Testing at 0%\n",
      "\tloss: 3.1354954801499844 \n",
      "\tval_loss: 5.477535367012024\n",
      "Epoch 335: Training done. Testing at 0%\n",
      "\tloss: 3.4627687223255634 \n",
      "\tval_loss: 5.475701808929443\n",
      "Epoch 336: Training done. Testing at 0%\n",
      "\tloss: 3.141078881919384 \n",
      "\tval_loss: 5.478209495544434\n",
      "Epoch 337: Training done. Testing at 0%\n",
      "\tloss: 3.0918487003073096 \n",
      "\tval_loss: 5.4861356019973755\n",
      "Epoch 338: Training done. Testing at 0%\n",
      "\tloss: 3.171809713356197 \n",
      "\tval_loss: 5.491586208343506\n",
      "Epoch 339: Training done. Testing at 0%\n",
      "\tloss: 3.0271566063165665 \n",
      "\tval_loss: 5.494194388389587\n",
      "Epoch 340: Training done. Testing at 0%\n",
      "\tloss: 3.0779428659006953 \n",
      "\tval_loss: 5.500241160392761\n",
      "Epoch 341: Training done. Testing at 0%\n",
      "\tloss: 3.1510046618059278 \n",
      "\tval_loss: 5.5020575523376465\n",
      "Epoch 342: Training done. Testing at 0%\n",
      "\tloss: 2.9833647524937987 \n",
      "\tval_loss: 5.504127860069275\n",
      "Epoch 343: Training done. Testing at 0%\n",
      "\tloss: 3.1431207731366158 \n",
      "\tval_loss: 5.505606651306152\n",
      "Epoch 344: Training done. Testing at 0%\n",
      "\tloss: 3.048900513909757 \n",
      "\tval_loss: 5.515282988548279\n",
      "Epoch 345: Training done. Testing at 0%\n",
      "\tloss: 3.076650015078485 \n",
      "\tval_loss: 5.5260089635849\n",
      "Epoch 346: Training done. Testing at 0%\n",
      "\tloss: 3.323567882180214 \n",
      "\tval_loss: 5.53007447719574\n",
      "Epoch 347: Training done. Testing at 0%\n",
      "\tloss: 3.059925328940153 \n",
      "\tval_loss: 5.526745319366455\n",
      "Epoch 348: Training done. Testing at 0%\n",
      "\tloss: 3.1184346387162805 \n",
      "\tval_loss: 5.529359221458435\n",
      "Epoch 349: Training done. Testing at 0%\n",
      "\tloss: 3.0518888998776674 \n",
      "\tval_loss: 5.523122191429138\n",
      "Epoch 350: Training done. Testing at 0%\n",
      "\tloss: 2.9665874680504203 \n",
      "\tval_loss: 5.52765691280365\n",
      "Epoch 351: Training done. Testing at 0%\n",
      "\tloss: 3.1000723280012608 \n",
      "\tval_loss: 5.530272603034973\n",
      "Epoch 352: Training done. Testing at 0%\n",
      "\tloss: 2.9599006678909063 \n",
      "\tval_loss: 5.536152005195618\n",
      "Epoch 353: Training done. Testing at 0%\n",
      "\tloss: 3.018928911536932 \n",
      "\tval_loss: 5.542209506034851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354: Training done. Testing at 0%\n",
      "\tloss: 3.0587665010243654 \n",
      "\tval_loss: 5.542835712432861\n",
      "Epoch 355: Training done. Testing at 0%\n",
      "\tloss: 3.284401984885335 \n",
      "\tval_loss: 5.545742154121399\n",
      "Epoch 356: Training done. Testing at 0%\n",
      "\tloss: 2.9190767416730523 \n",
      "\tval_loss: 5.553303837776184\n",
      "Epoch 357: Training done. Testing at 0%\n",
      "\tloss: 2.868356216698885 \n",
      "\tval_loss: 5.564898133277893\n",
      "Epoch 358: Training done. Testing at 0%\n",
      "\tloss: 2.893125276081264 \n",
      "\tval_loss: 5.567363619804382\n",
      "Epoch 359: Training done. Testing at 0%\n",
      "\tloss: 2.8657527081668377 \n",
      "\tval_loss: 5.56656539440155\n",
      "Epoch 360: Training done. Testing at 0%\n",
      "\tloss: 2.860856863670051 \n",
      "\tval_loss: 5.570022225379944\n",
      "Epoch 361: Training done. Testing at 0%\n",
      "\tloss: 2.98402641993016 \n",
      "\tval_loss: 5.565962791442871\n",
      "Epoch 362: Training done. Testing at 0%\n",
      "\tloss: 2.8575171818956733 \n",
      "\tval_loss: 5.565958857536316\n",
      "Epoch 363: Training done. Testing at 0%\n",
      "\tloss: 2.8246537521481514 \n",
      "\tval_loss: 5.568579196929932\n",
      "Epoch 364: Training done. Testing at 0%\n",
      "\tloss: 3.0687726950272918 \n",
      "\tval_loss: 5.571051478385925\n",
      "Epoch 365: Training done. Testing at 0%\n",
      "\tloss: 2.8715470703318715 \n",
      "\tval_loss: 5.5806344747543335\n",
      "Epoch 366: Training done. Testing at 0%\n",
      "\tloss: 2.9167528925463557 \n",
      "\tval_loss: 5.582513451576233\n",
      "Epoch 367: Training done. Testing at 0%\n",
      "\tloss: 2.8315631402656436 \n",
      "\tval_loss: 5.5865478515625\n",
      "Epoch 368: Training done. Testing at 0%\n",
      "\tloss: 2.8026298275217414 \n",
      "\tval_loss: 5.586765289306641\n",
      "Epoch 369: Training done. Testing at 0%\n",
      "\tloss: 2.8363435519859195 \n",
      "\tval_loss: 5.583529472351074\n",
      "Epoch 370: Training done. Testing at 0%\n",
      "\tloss: 2.878752456046641 \n",
      "\tval_loss: 5.58632218837738\n",
      "Epoch 371: Training done. Testing at 0%\n",
      "\tloss: 2.7359349029138684 \n",
      "\tval_loss: 5.595037937164307\n",
      "Epoch 372: Training done. Testing at 0%\n",
      "\tloss: 3.1660416051745415 \n",
      "\tval_loss: 5.597676157951355\n",
      "Epoch 373: Training done. Testing at 0%\n",
      "\tloss: 2.988655973225832 \n",
      "\tval_loss: 5.60552179813385\n",
      "Epoch 374: Training done. Testing at 0%\n",
      "\tloss: 2.841811940073967 \n",
      "\tval_loss: 5.6239800453186035\n",
      "Epoch 375: Training done. Testing at 0%\n",
      "\tloss: 2.8486491991207004 \n",
      "\tval_loss: 5.632665038108826\n",
      "Epoch 376: Training done. Testing at 0%\n",
      "\tloss: 2.843323178589344 \n",
      "\tval_loss: 5.627567768096924\n",
      "Epoch 377: Training done. Testing at 0%\n",
      "\tloss: 2.93443307466805 \n",
      "\tval_loss: 5.629068732261658\n",
      "Epoch 378: Training done. Testing at 0%\n",
      "\tloss: 3.0299231791868806 \n",
      "\tval_loss: 5.627367854118347\n",
      "Epoch 379: Training done. Testing at 0%\n",
      "\tloss: 3.0359388617798686 \n",
      "\tval_loss: 5.638627409934998\n",
      "Epoch 380: Training done. Testing at 0%\n",
      "\tloss: 2.904341673478484 \n",
      "\tval_loss: 5.6447625160217285\n",
      "Epoch 381: Training done. Testing at 0%\n",
      "\tloss: 2.716895280405879 \n",
      "\tval_loss: 5.648792624473572\n",
      "Epoch 382: Training done. Testing at 0%\n",
      "\tloss: 2.8674692697823048 \n",
      "\tval_loss: 5.654422760009766\n",
      "Epoch 383: Training done. Testing at 0%\n",
      "\tloss: 2.800357519648969 \n",
      "\tval_loss: 5.6461029052734375\n",
      "Epoch 384: Training done. Testing at 0%\n",
      "\tloss: 2.841648645699024 \n",
      "\tval_loss: 5.647037029266357\n",
      "Epoch 385: Training done. Testing at 0%\n",
      "\tloss: 2.681104203686118 \n",
      "\tval_loss: 5.650325775146484\n",
      "Epoch 386: Training done. Testing at 0%\n",
      "\tloss: 2.7131256572902203 \n",
      "\tval_loss: 5.653623104095459\n",
      "Epoch 387: Training done. Testing at 0%\n",
      "\tloss: 2.6457340214401484 \n",
      "\tval_loss: 5.660060405731201\n",
      "Epoch 388: Training done. Testing at 0%\n",
      "\tloss: 2.7244293922558427 \n",
      "\tval_loss: 5.662771582603455\n",
      "Epoch 389: Training done. Testing at 0%\n",
      "\tloss: 2.9146182974800467 \n",
      "\tval_loss: 5.670100808143616\n",
      "Epoch 390: Training done. Testing at 0%\n",
      "\tloss: 2.6719159241765738 \n",
      "\tval_loss: 5.668062686920166\n",
      "Epoch 391: Training done. Testing at 0%\n",
      "\tloss: 2.589065791107714 \n",
      "\tval_loss: 5.672322750091553\n",
      "Epoch 392: Training done. Testing at 0%\n",
      "\tloss: 2.5567149398848414 \n",
      "\tval_loss: 5.678747177124023\n",
      "Epoch 393: Training done. Testing at 0%\n",
      "\tloss: 2.851514793932438 \n",
      "\tval_loss: 5.682033061981201\n",
      "Epoch 394: Training done. Testing at 0%\n",
      "\tloss: 2.7595303766429424 \n",
      "\tval_loss: 5.689279675483704\n",
      "Epoch 395: Training done. Testing at 0%\n",
      "\tloss: 2.869884567335248 \n",
      "\tval_loss: 5.686279892921448\n",
      "Epoch 396: Training done. Testing at 0%\n",
      "\tloss: 2.6139280647039413 \n",
      "\tval_loss: 5.687323093414307\n",
      "Epoch 397: Training done. Testing at 0%\n",
      "\tloss: 2.639121435582638 \n",
      "\tval_loss: 5.6852720975875854\n",
      "Epoch 398: Training done. Testing at 0%\n",
      "\tloss: 2.6708719907328486 \n",
      "\tval_loss: 5.68940269947052\n",
      "Epoch 399: Training done. Testing at 0%\n",
      "\tloss: 2.519659297540784 \n",
      "\tval_loss: 5.693657398223877\n",
      "Epoch 400: Training done. Testing at 0%\n",
      "\tloss: 2.6025118324905634 \n",
      "\tval_loss: 5.693189978599548\n",
      "Epoch 401: Training done. Testing at 0%\n",
      "\tloss: 2.5145119493827224 \n",
      "\tval_loss: 5.690532803535461\n",
      "Epoch 402: Training done. Testing at 0%\n",
      "\tloss: 2.5219803620129824 \n",
      "\tval_loss: 5.695143699645996\n",
      "Epoch 403: Training done. Testing at 0%\n",
      "\tloss: 2.5241368766874075 \n",
      "\tval_loss: 5.695276379585266\n",
      "Epoch 404: Training done. Testing at 0%\n",
      "\tloss: 2.520681405439973 \n",
      "\tval_loss: 5.692195773124695\n",
      "Epoch 405: Training done. Testing at 0%\n",
      "\tloss: 2.517130088992417 \n",
      "\tval_loss: 5.7034724950790405\n",
      "Epoch 406: Training done. Testing at 0%\n",
      "\tloss: 2.639881224371493 \n",
      "\tval_loss: 5.710527062416077\n",
      "Epoch 407: Training done. Testing at 0%\n",
      "\tloss: 2.831081544049084 \n",
      "\tval_loss: 5.714016795158386\n",
      "Epoch 408: Training done. Testing at 0%\n",
      "\tloss: 2.5742958122864366 \n",
      "\tval_loss: 5.717519760131836\n",
      "Epoch 409: Training done. Testing at 0%\n",
      "\tloss: 2.5347837964072824 \n",
      "\tval_loss: 5.7272855043411255\n",
      "Epoch 410: Training done. Testing at 0%\n",
      "\tloss: 2.4844910609535873 \n",
      "\tval_loss: 5.729651570320129\n",
      "Epoch 411: Training done. Testing at 0%\n",
      "\tloss: 2.5714091835543513 \n",
      "\tval_loss: 5.734732031822205\n",
      "Epoch 412: Training done. Testing at 0%\n",
      "\tloss: 2.606938198208809 \n",
      "\tval_loss: 5.736377120018005\n",
      "Epoch 413: Training done. Testing at 0%\n",
      "\tloss: 2.516677970997989 \n",
      "\tval_loss: 5.749606132507324\n",
      "Epoch 414: Training done. Testing at 0%\n",
      "\tloss: 2.5076739387586713 \n",
      "\tval_loss: 5.7551010847091675\n",
      "Epoch 415: Training done. Testing at 0%\n",
      "\tloss: 2.4841146832332015 \n",
      "\tval_loss: 5.7585707902908325\n",
      "Epoch 416: Training done. Testing at 0%\n",
      "\tloss: 2.5658291978761554 \n",
      "\tval_loss: 5.754379749298096\n",
      "Epoch 417: Training done. Testing at 0%\n",
      "\tloss: 2.4451840203255415 \n",
      "\tval_loss: 5.755680084228516\n",
      "Epoch 418: Training done. Testing at 0%\n",
      "\tloss: 2.4547355510294437 \n",
      "\tval_loss: 5.756538391113281\n",
      "Epoch 419: Training done. Testing at 0%\n",
      "\tloss: 2.524216014891863 \n",
      "\tval_loss: 5.759664058685303\n",
      "Epoch 420: Training done. Testing at 0%\n",
      "\tloss: 2.646533857099712 \n",
      "\tval_loss: 5.749858975410461\n",
      "Epoch 421: Training done. Testing at 0%\n",
      "\tloss: 2.764103874564171 \n",
      "\tval_loss: 5.753357291221619\n",
      "Epoch 422: Training done. Testing at 0%\n",
      "\tloss: 2.3688070084899664 \n",
      "\tval_loss: 5.758720278739929\n",
      "Epoch 423: Training done. Testing at 0%\n",
      "\tloss: 2.514478695578873 \n",
      "\tval_loss: 5.768641948699951\n",
      "Epoch 424: Training done. Testing at 0%\n",
      "\tloss: 2.4290450708940625 \n",
      "\tval_loss: 5.777841925621033\n",
      "Epoch 425: Training done. Testing at 0%\n",
      "\tloss: 2.416203875094652 \n",
      "\tval_loss: 5.792019009590149\n",
      "Epoch 426: Training done. Testing at 0%\n",
      "\tloss: 2.4104735823348165 \n",
      "\tval_loss: 5.791497588157654\n",
      "Epoch 427: Training done. Testing at 0%\n",
      "\tloss: 2.2442579437047243 \n",
      "\tval_loss: 5.79071581363678\n",
      "Epoch 428: Training done. Testing at 0%\n",
      "\tloss: 2.4493973162025213 \n",
      "\tval_loss: 5.799595355987549\n",
      "Epoch 429: Training done. Testing at 0%\n",
      "\tloss: 2.4474609503522515 \n",
      "\tval_loss: 5.796851634979248\n",
      "Epoch 430: Training done. Testing at 0%\n",
      "\tloss: 2.460575013421476 \n",
      "\tval_loss: 5.79932963848114\n",
      "Epoch 431: Training done. Testing at 0%\n",
      "\tloss: 2.239928792230785 \n",
      "\tval_loss: 5.800130009651184\n",
      "Epoch 432: Training done. Testing at 0%\n",
      "\tloss: 2.338310832157731 \n",
      "\tval_loss: 5.80034065246582\n",
      "Epoch 433: Training done. Testing at 0%\n",
      "\tloss: 2.2914934623986483 \n",
      "\tval_loss: 5.797993183135986\n",
      "Epoch 434: Training done. Testing at 0%\n",
      "\tloss: 2.336854607798159 \n",
      "\tval_loss: 5.8000041246414185\n",
      "Epoch 435: Training done. Testing at 0%\n",
      "\tloss: 2.3733238778077066 \n",
      "\tval_loss: 5.798646926879883\n",
      "Epoch 436: Training done. Testing at 0%\n",
      "\tloss: 2.390482911840081 \n",
      "\tval_loss: 5.804642200469971\n",
      "Epoch 437: Training done. Testing at 0%\n",
      "\tloss: 2.4780740765854716 \n",
      "\tval_loss: 5.809722304344177\n",
      "Epoch 438: Training done. Testing at 0%\n",
      "\tloss: 2.3089787866920233 \n",
      "\tval_loss: 5.816707134246826\n",
      "Epoch 439: Training done. Testing at 0%\n",
      "\tloss: 2.264883302617818 \n",
      "\tval_loss: 5.82487428188324\n",
      "Epoch 440: Training done. Testing at 0%\n",
      "\tloss: 2.1952888825908303 \n",
      "\tval_loss: 5.826633810997009\n",
      "Epoch 441: Training done. Testing at 0%\n",
      "\tloss: 2.4470064947381616 \n",
      "\tval_loss: 5.834030985832214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442: Training done. Testing at 0%\n",
      "\tloss: 2.3038607137277722 \n",
      "\tval_loss: 5.840951442718506\n",
      "Epoch 443: Training done. Testing at 0%\n",
      "\tloss: 2.2145656859502196 \n",
      "\tval_loss: 5.841320514678955\n",
      "Epoch 444: Training done. Testing at 0%\n",
      "\tloss: 2.4400879610329866 \n",
      "\tval_loss: 5.841260075569153\n",
      "Epoch 445: Training done. Testing at 0%\n",
      "\tloss: 2.3682110887020826 \n",
      "\tval_loss: 5.8404436111450195\n",
      "Epoch 446: Training done. Testing at 0%\n",
      "\tloss: 2.3849586555734277 \n",
      "\tval_loss: 5.843224883079529\n",
      "Epoch 447: Training done. Testing at 0%\n",
      "\tloss: 2.1904289284721017 \n",
      "\tval_loss: 5.840732574462891\n",
      "Epoch 448: Training done. Testing at 0%\n",
      "\tloss: 2.1962760807946324 \n",
      "\tval_loss: 5.839128613471985\n",
      "Epoch 449: Training done. Testing at 0%\n",
      "\tloss: 2.2173619838431478 \n",
      "\tval_loss: 5.837465286254883\n",
      "Epoch 450: Training done. Testing at 0%\n",
      "\tloss: 2.2136220103129745 \n",
      "\tval_loss: 5.843792080879211\n",
      "Epoch 451: Training done. Testing at 0%\n",
      "\tloss: 2.1606735289096832 \n",
      "\tval_loss: 5.846643090248108\n",
      "Epoch 452: Training done. Testing at 0%\n",
      "\tloss: 2.3694915222004056 \n",
      "\tval_loss: 5.85932457447052\n",
      "Epoch 453: Training done. Testing at 0%\n",
      "\tloss: 2.236910323612392 \n",
      "\tval_loss: 5.86352813243866\n",
      "Epoch 454: Training done. Testing at 0%\n",
      "\tloss: 2.1159942811354995 \n",
      "\tval_loss: 5.860422492027283\n",
      "Epoch 455: Training done. Testing at 0%\n",
      "\tloss: 2.235013395547867 \n",
      "\tval_loss: 5.860104203224182\n",
      "Epoch 456: Training done. Testing at 0%\n",
      "\tloss: 2.1814242396503687 \n",
      "\tval_loss: 5.862754940986633\n",
      "Epoch 457: Training done. Testing at 0%\n",
      "\tloss: 2.390883933752775 \n",
      "\tval_loss: 5.862566828727722\n",
      "Epoch 458: Training done. Testing at 0%\n",
      "\tloss: 2.1170926336199045 \n",
      "\tval_loss: 5.869417190551758\n",
      "Epoch 459: Training done. Testing at 0%\n",
      "\tloss: 2.1137188198044896 \n",
      "\tval_loss: 5.872140526771545\n",
      "Epoch 460: Training done. Testing at 0%\n",
      "\tloss: 2.1088058040477335 \n",
      "\tval_loss: 5.874705791473389\n",
      "Epoch 461: Training done. Testing at 0%\n",
      "\tloss: 2.4880289854481816 \n",
      "\tval_loss: 5.8769835233688354\n",
      "Epoch 462: Training done. Testing at 0%\n",
      "\tloss: 2.1255611907690763 \n",
      "\tval_loss: 5.879314541816711\n",
      "Epoch 463: Training done. Testing at 0%\n",
      "\tloss: 2.291443446651101 \n",
      "\tval_loss: 5.878231644630432\n",
      "Epoch 464: Training done. Testing at 0%\n",
      "\tloss: 2.1982574933208525 \n",
      "\tval_loss: 5.877465605735779\n",
      "Epoch 465: Training done. Testing at 0%\n",
      "\tloss: 2.124843258410692 \n",
      "\tval_loss: 5.8857035636901855\n",
      "Epoch 466: Training done. Testing at 0%\n",
      "\tloss: 2.218347385060042 \n",
      "\tval_loss: 5.891137719154358\n",
      "Epoch 467: Training done. Testing at 0%\n",
      "\tloss: 2.0522542651742697 \n",
      "\tval_loss: 5.895338416099548\n",
      "Epoch 468: Training done. Testing at 0%\n",
      "\tloss: 2.040230570361018 \n",
      "\tval_loss: 5.899698615074158\n",
      "Epoch 469: Training done. Testing at 0%\n",
      "\tloss: 2.124075031839311 \n",
      "\tval_loss: 5.9035409688949585\n",
      "Epoch 470: Training done. Testing at 0%\n",
      "\tloss: 2.0782473841682076 \n",
      "\tval_loss: 5.903314590454102\n",
      "Epoch 471: Training done. Testing at 0%\n",
      "\tloss: 2.052754600532353 \n",
      "\tval_loss: 5.8987226486206055\n",
      "Epoch 472: Training done. Testing at 0%\n",
      "\tloss: 2.1105766692198813 \n",
      "\tval_loss: 5.9000115394592285\n",
      "Epoch 473: Training done. Testing at 0%\n",
      "\tloss: 2.0778786782175303 \n",
      "\tval_loss: 5.909641742706299\n",
      "Epoch 474: Training done. Testing at 0%\n",
      "\tloss: 2.0661044381558895 \n",
      "\tval_loss: 5.913248062133789\n",
      "Epoch 475: Training done. Testing at 0%\n",
      "\tloss: 2.0920565985143185 \n",
      "\tval_loss: 5.921641945838928\n",
      "Epoch 476: Training done. Testing at 0%\n",
      "\tloss: 2.2050381815060973 \n",
      "\tval_loss: 5.928936839103699\n",
      "Epoch 477: Training done. Testing at 0%\n",
      "\tloss: 2.0036451392807066 \n",
      "\tval_loss: 5.936612248420715\n",
      "Epoch 478: Training done. Testing at 0%\n",
      "\tloss: 2.1077170399948955 \n",
      "\tval_loss: 5.939216136932373\n",
      "Epoch 479: Training done. Testing at 0%\n",
      "\tloss: 2.1859059506095946 \n",
      "\tval_loss: 5.942776322364807\n",
      "Epoch 480: Training done. Testing at 0%\n",
      "\tloss: 2.1095365080982447 \n",
      "\tval_loss: 5.940883040428162\n",
      "Epoch 481: Training done. Testing at 0%\n",
      "\tloss: 2.0317527977749705 \n",
      "\tval_loss: 5.9456480741500854\n",
      "Epoch 482: Training done. Testing at 0%\n",
      "\tloss: 2.030564706772566 \n",
      "\tval_loss: 5.944629549980164\n",
      "Epoch 483: Training done. Testing at 0%\n",
      "\tloss: 2.05152618419379 \n",
      "\tval_loss: 5.9481199979782104\n",
      "Epoch 484: Training done. Testing at 0%\n",
      "\tloss: 1.9752330482006073 \n",
      "\tval_loss: 5.948620319366455\n",
      "Epoch 485: Training done. Testing at 0%\n",
      "\tloss: 1.9762724908068776 \n",
      "\tval_loss: 5.950992107391357\n",
      "Epoch 486: Training done. Testing at 0%\n",
      "\tloss: 1.9771932805888355 \n",
      "\tval_loss: 5.953392505645752\n",
      "Epoch 487: Training done. Testing at 0%\n",
      "\tloss: 2.2058821534737945 \n",
      "\tval_loss: 5.958236575126648\n",
      "Epoch 488: Training done. Testing at 0%\n",
      "\tloss: 1.9419832532294095 \n",
      "\tval_loss: 5.962584614753723\n",
      "Epoch 489: Training done. Testing at 0%\n",
      "\tloss: 1.9258678192272782 \n",
      "\tval_loss: 5.966233134269714\n",
      "Epoch 490: Training done. Testing at 0%\n",
      "\tloss: 1.9222363959997892 \n",
      "\tval_loss: 5.967942237854004\n",
      "Epoch 491: Training done. Testing at 0%\n",
      "\tloss: 1.9705722499638796 \n",
      "\tval_loss: 5.971610426902771\n",
      "Epoch 492: Training done. Testing at 0%\n",
      "\tloss: 1.9885519882664084 \n",
      "\tval_loss: 5.971862196922302\n",
      "Epoch 493: Training done. Testing at 0%\n",
      "\tloss: 2.0025058267638087 \n",
      "\tval_loss: 5.9733957052230835\n",
      "Epoch 494: Training done. Testing at 0%\n",
      "\tloss: 1.9243670152500272 \n",
      "\tval_loss: 5.972955107688904\n",
      "Epoch 495: Training done. Testing at 0%\n",
      "\tloss: 2.109675525687635 \n",
      "\tval_loss: 5.978919982910156\n",
      "Epoch 496: Training done. Testing at 0%\n",
      "\tloss: 1.943997660651803 \n",
      "\tval_loss: 5.983486533164978\n",
      "Epoch 497: Training done. Testing at 0%\n",
      "\tloss: 2.1511791707016528 \n",
      "\tval_loss: 5.989932060241699\n",
      "Epoch 498: Training done. Testing at 0%\n",
      "\tloss: 1.9824671889655292 \n",
      "\tval_loss: 5.997604250907898\n",
      "Epoch 499: Training done. Testing at 0%\n",
      "\tloss: 2.063765403814614 \n",
      "\tval_loss: 5.999541878700256\n",
      "Epoch 500: Training done. Testing at 0%\n",
      "\tloss: 1.9816273250617087 \n",
      "\tval_loss: 5.996346473693848\n",
      "Epoch 501: Training done. Testing at 0%\n",
      "\tloss: 2.2578611755743623 \n",
      "\tval_loss: 5.997566342353821\n",
      "Epoch 502: Training done. Testing at 0%\n",
      "\tloss: 2.0055925007909536 \n",
      "\tval_loss: 5.99589478969574\n",
      "Epoch 503: Training done. Testing at 0%\n",
      "\tloss: 2.162248264066875 \n",
      "\tval_loss: 5.9890090227127075\n",
      "Epoch 504: Training done. Testing at 0%\n",
      "\tloss: 2.0025285435840487 \n",
      "\tval_loss: 5.995282173156738\n",
      "Epoch 505: Training done. Testing at 0%\n",
      "\tloss: 1.9860089514404535 \n",
      "\tval_loss: 5.997004866600037\n",
      "Epoch 506: Training done. Testing at 0%\n",
      "\tloss: 1.8740624892525375 \n",
      "\tval_loss: 6.001322507858276\n",
      "Epoch 507: Training done. Testing at 0%\n",
      "\tloss: 1.8956635696813464 \n",
      "\tval_loss: 6.0043909549713135\n",
      "Epoch 508: Training done. Testing at 0%\n",
      "\tloss: 1.955007903277874 \n",
      "\tval_loss: 6.0011537075042725\n",
      "Epoch 509: Training done. Testing at 0%\n",
      "\tloss: 1.8938366835936904 \n",
      "\tval_loss: 6.0075109004974365\n",
      "Epoch 510: Training done. Testing at 0%\n",
      "\tloss: 1.90344469062984 \n",
      "\tval_loss: 6.017967939376831\n",
      "Epoch 511: Training done. Testing at 0%\n",
      "\tloss: 1.8713762098923326 \n",
      "\tval_loss: 6.017730474472046\n",
      "Epoch 512: Training done. Testing at 0%\n",
      "\tloss: 1.8546567913144827 \n",
      "\tval_loss: 6.022930383682251\n",
      "Epoch 513: Training done. Testing at 0%\n",
      "\tloss: 1.8015230866149068 \n",
      "\tval_loss: 6.025087594985962\n",
      "Epoch 514: Training done. Testing at 0%\n",
      "\tloss: 2.060561951249838 \n",
      "\tval_loss: 6.028764724731445\n",
      "Epoch 515: Training done. Testing at 0%\n",
      "\tloss: 1.8850893583148718 \n",
      "\tval_loss: 6.029264688491821\n",
      "Epoch 516: Training done. Testing at 0%\n",
      "\tloss: 1.9093943890184164 \n",
      "\tval_loss: 6.0333781242370605\n",
      "Epoch 517: Training done. Testing at 0%\n",
      "\tloss: 1.800963961519301 \n",
      "\tval_loss: 6.035126209259033\n",
      "Epoch 518: Training done. Testing at 0%\n",
      "\tloss: 1.8476228825747967 \n",
      "\tval_loss: 6.043736457824707\n",
      "Epoch 519: Training done. Testing at 0%\n",
      "\tloss: 1.9478753749281168 \n",
      "\tval_loss: 6.050145864486694\n",
      "Epoch 520: Training done. Testing at 0%\n",
      "\tloss: 1.902469021268189 \n",
      "\tval_loss: 6.054931640625\n",
      "Epoch 521: Training done. Testing at 0%\n",
      "\tloss: 1.8849942474626005 \n",
      "\tval_loss: 6.064472436904907\n",
      "Epoch 522: Training done. Testing at 0%\n",
      "\tloss: 1.9789256760850549 \n",
      "\tval_loss: 6.0692760944366455\n",
      "Epoch 523: Training done. Testing at 0%\n",
      "\tloss: 1.8214607136324048 \n",
      "\tval_loss: 6.063644886016846\n",
      "Epoch 524: Training done. Testing at 0%\n",
      "\tloss: 1.8866565525531769 \n",
      "\tval_loss: 6.06774115562439\n",
      "Epoch 525: Training done. Testing at 0%\n",
      "\tloss: 1.9281221805140376 \n",
      "\tval_loss: 6.060863971710205\n",
      "Epoch 526: Training done. Testing at 0%\n",
      "\tloss: 1.8652328797616065 \n",
      "\tval_loss: 6.059818267822266\n",
      "Epoch 527: Training done. Testing at 0%\n",
      "\tloss: 1.8338688993826509 \n",
      "\tval_loss: 6.06085467338562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528: Training done. Testing at 0%\n",
      "\tloss: 1.8326911726035178 \n",
      "\tval_loss: 6.064513921737671\n",
      "Epoch 529: Training done. Testing at 0%\n",
      "\tloss: 1.80965893343091 \n",
      "\tval_loss: 6.065851449966431\n",
      "Epoch 530: Training done. Testing at 0%\n",
      "\tloss: 1.7150911893695593 \n",
      "\tval_loss: 6.071142911911011\n",
      "Epoch 531: Training done. Testing at 0%\n",
      "\tloss: 1.934510632418096 \n",
      "\tval_loss: 6.079993486404419\n",
      "Epoch 532: Training done. Testing at 0%\n",
      "\tloss: 1.7659975243732333 \n",
      "\tval_loss: 6.087424278259277\n",
      "Epoch 533: Training done. Testing at 0%\n",
      "\tloss: 1.77610716316849 \n",
      "\tval_loss: 6.084981679916382\n",
      "Epoch 534: Training done. Testing at 0%\n",
      "\tloss: 1.7542132786475122 \n",
      "\tval_loss: 6.090697288513184\n",
      "Epoch 535: Training done. Testing at 0%\n",
      "\tloss: 1.8027728591114283 \n",
      "\tval_loss: 6.091484069824219\n",
      "Epoch 536: Training done. Testing at 0%\n",
      "\tloss: 1.692506970372051 \n",
      "\tval_loss: 6.097006559371948\n",
      "Epoch 537: Training done. Testing at 0%\n",
      "\tloss: 1.7279777312651277 \n",
      "\tval_loss: 6.103802919387817\n",
      "Epoch 538: Training done. Testing at 0%\n",
      "\tloss: 1.6866772784851491 \n",
      "\tval_loss: 6.1009840965271\n",
      "Epoch 539: Training done. Testing at 0%\n",
      "\tloss: 1.8928931443952024 \n",
      "\tval_loss: 6.101644992828369\n",
      "Epoch 540: Training done. Testing at 0%\n",
      "\tloss: 1.7166040590964258 \n",
      "\tval_loss: 6.104435205459595\n",
      "Epoch 541: Training done. Testing at 0%\n",
      "\tloss: 1.8086047167889774 \n",
      "\tval_loss: 6.108673810958862\n",
      "Epoch 542: Training done. Testing at 0%\n",
      "\tloss: 1.7984987618401647 \n",
      "\tval_loss: 6.120243072509766\n",
      "Epoch 543: Training done. Testing at 0%\n",
      "\tloss: 1.7234934950247407 \n",
      "\tval_loss: 6.127702474594116\n",
      "Epoch 544: Training done. Testing at 0%\n",
      "\tloss: 1.746525610331446 \n",
      "\tval_loss: 6.1239402294158936\n",
      "Epoch 545: Training done. Testing at 0%\n",
      "\tloss: 1.7830118793062866 \n",
      "\tval_loss: 6.122154235839844\n",
      "Epoch 546: Training done. Testing at 0%\n",
      "\tloss: 1.6509910668246448 \n",
      "\tval_loss: 6.126602411270142\n",
      "Epoch 547: Training done. Testing at 0%\n",
      "\tloss: 1.7218677131459117 \n",
      "\tval_loss: 6.1263628005981445\n",
      "Epoch 548: Training done. Testing at 0%\n",
      "\tloss: 1.968454237561673 \n",
      "\tval_loss: 6.125479459762573\n",
      "Epoch 549: Training done. Testing at 0%\n",
      "\tloss: 1.7515021692961454 \n",
      "\tval_loss: 6.126407146453857\n",
      "Epoch 550: Training done. Testing at 0%\n",
      "\tloss: 1.9326985217630863 \n",
      "\tval_loss: 6.128430604934692\n",
      "Epoch 551: Training done. Testing at 0%\n",
      "\tloss: 1.7290087109431624 \n",
      "\tval_loss: 6.131254434585571\n",
      "Epoch 552: Training done. Testing at 0%\n",
      "\tloss: 1.617281793616712 \n",
      "\tval_loss: 6.135797739028931\n",
      "Epoch 553: Training done. Testing at 0%\n",
      "\tloss: 1.6029945220798254 \n",
      "\tval_loss: 6.142242193222046\n",
      "Epoch 554: Training done. Testing at 0%\n",
      "\tloss: 1.7902490450069308 \n",
      "\tval_loss: 6.154294967651367\n",
      "Epoch 555: Training done. Testing at 0%\n",
      "\tloss: 1.7063478217460215 \n",
      "\tval_loss: 6.159614324569702\n",
      "Epoch 556: Training done. Testing at 0%\n",
      "\tloss: 1.7227846523746848 \n",
      "\tval_loss: 6.163156986236572\n",
      "Epoch 557: Training done. Testing at 0%\n",
      "\tloss: 1.7312658447772264 \n",
      "\tval_loss: 6.168694496154785\n",
      "Epoch 558: Training done. Testing at 0%\n",
      "\tloss: 1.6712146629579365 \n",
      "\tval_loss: 6.1772847175598145\n",
      "Epoch 559: Training done. Testing at 0%\n",
      "\tloss: 1.6522104111500084 \n",
      "\tval_loss: 6.177443504333496\n",
      "Epoch 560: Training done. Testing at 0%\n",
      "\tloss: 1.616407010704279 \n",
      "\tval_loss: 6.176953554153442\n",
      "Epoch 561: Training done. Testing at 0%\n",
      "\tloss: 1.655369893182069 \n",
      "\tval_loss: 6.1837427616119385\n",
      "Epoch 562: Training done. Testing at 0%\n",
      "\tloss: 1.5575633677653968 \n",
      "\tval_loss: 6.188260316848755\n",
      "Epoch 563: Training done. Testing at 0%\n",
      "\tloss: 1.6460415506735444 \n",
      "\tval_loss: 6.188024997711182\n",
      "Epoch 564: Training done. Testing at 0%\n",
      "\tloss: 1.6227145325392485 \n",
      "\tval_loss: 6.185023069381714\n",
      "Epoch 565: Training done. Testing at 0%\n",
      "\tloss: 1.575648974161595 \n",
      "\tval_loss: 6.180702209472656\n",
      "Epoch 566: Training done. Testing at 0%\n",
      "\tloss: 1.5658215573057532 \n",
      "\tval_loss: 6.178003549575806\n",
      "Epoch 567: Training done. Testing at 0%\n",
      "\tloss: 1.595965248066932 \n",
      "\tval_loss: 6.18064284324646\n",
      "Epoch 568: Training done. Testing at 0%\n",
      "\tloss: 1.6675104461610317 \n",
      "\tval_loss: 6.1839659214019775\n",
      "Epoch 569: Training done. Testing at 0%\n",
      "\tloss: 1.5890340353362262 \n",
      "\tval_loss: 6.189866065979004\n",
      "Epoch 570: Training done. Testing at 0%\n",
      "\tloss: 1.7474389988929033 \n",
      "\tval_loss: 6.191160678863525\n",
      "Epoch 571: Training done. Testing at 0%\n",
      "\tloss: 1.5553968637250364 \n",
      "\tval_loss: 6.188173055648804\n",
      "Epoch 572: Training done. Testing at 0%\n",
      "\tloss: 1.6783155552111566 \n",
      "\tval_loss: 6.187207460403442\n",
      "Epoch 573: Training done. Testing at 0%\n",
      "\tloss: 1.5558580989018083 \n",
      "\tval_loss: 6.183267116546631\n",
      "Epoch 574: Training done. Testing at 0%\n",
      "\tloss: 1.5726001276634634 \n",
      "\tval_loss: 6.188868284225464\n",
      "Epoch 575: Training done. Testing at 0%\n",
      "\tloss: 1.5764367640949786 \n",
      "\tval_loss: 6.196176767349243\n",
      "Epoch 576: Training done. Testing at 0%\n",
      "\tloss: 1.7706395969726145 \n",
      "\tval_loss: 6.194724798202515\n",
      "Epoch 577: Training done. Testing at 0%\n",
      "\tloss: 1.4981665243394673 \n",
      "\tval_loss: 6.200147867202759\n",
      "Epoch 578: Training done. Testing at 0%\n",
      "\tloss: 1.6148096257820725 \n",
      "\tval_loss: 6.204927921295166\n",
      "Epoch 579: Training done. Testing at 0%\n",
      "\tloss: 1.6699038953520358 \n",
      "\tval_loss: 6.207746744155884\n",
      "Epoch 580: Training done. Testing at 0%\n",
      "\tloss: 1.6082654604688287 \n",
      "\tval_loss: 6.2205119132995605\n",
      "Epoch 581: Training done. Testing at 0%\n",
      "\tloss: 1.5897513255476952 \n",
      "\tval_loss: 6.228989839553833\n",
      "Epoch 582: Training done. Testing at 0%\n",
      "\tloss: 1.6139076831750572 \n",
      "\tval_loss: 6.228590726852417\n",
      "Epoch 583: Training done. Testing at 0%\n",
      "\tloss: 1.6180091220885515 \n",
      "\tval_loss: 6.230644941329956\n",
      "Epoch 584: Training done. Testing at 0%\n",
      "\tloss: 1.5016496791504323 \n",
      "\tval_loss: 6.230527639389038\n",
      "Epoch 585: Training done. Testing at 0%\n",
      "\tloss: 1.4885559151880443 \n",
      "\tval_loss: 6.227613687515259\n",
      "Epoch 586: Training done. Testing at 0%\n",
      "\tloss: 1.5850815339945257 \n",
      "\tval_loss: 6.237040758132935\n",
      "Epoch 587: Training done. Testing at 0%\n",
      "\tloss: 1.500949343200773 \n",
      "\tval_loss: 6.2406370639801025\n",
      "Epoch 588: Training done. Testing at 0%\n",
      "\tloss: 1.5121968151070178 \n",
      "\tval_loss: 6.239166498184204\n",
      "Epoch 589: Training done. Testing at 0%\n",
      "\tloss: 1.601844442076981 \n",
      "\tval_loss: 6.244104623794556\n",
      "Epoch 590: Training done. Testing at 0%\n",
      "\tloss: 1.5360577018000185 \n",
      "\tval_loss: 6.245633125305176\n",
      "Epoch 591: Training done. Testing at 0%\n",
      "\tloss: 1.563363738823682 \n",
      "\tval_loss: 6.248966217041016\n",
      "Epoch 592: Training done. Testing at 0%\n",
      "\tloss: 1.4786043600179255 \n",
      "\tval_loss: 6.245076656341553\n",
      "Epoch 593: Training done. Testing at 0%\n",
      "\tloss: 1.4906135573983192 \n",
      "\tval_loss: 6.238369703292847\n",
      "Epoch 594: Training done. Testing at 0%\n",
      "\tloss: 1.885593512095511 \n",
      "\tval_loss: 6.249763011932373\n",
      "Epoch 595: Training done. Testing at 0%\n",
      "\tloss: 1.4633301915600896 \n",
      "\tval_loss: 6.259979009628296\n",
      "Epoch 596: Training done. Testing at 0%\n",
      "\tloss: 1.4413821185007691 \n",
      "\tval_loss: 6.264611005783081\n",
      "Epoch 597: Training done. Testing at 0%\n",
      "\tloss: 1.4646655386313796 \n",
      "\tval_loss: 6.268821716308594\n",
      "Epoch 598: Training done. Testing at 0%\n",
      "\tloss: 1.4381710062734783 \n",
      "\tval_loss: 6.272169828414917\n",
      "Epoch 599: Training done. Testing at 0%\n",
      "\tloss: 1.6818568687886 \n",
      "\tval_loss: 6.270772218704224\n",
      "Epoch 600: Training done. Testing at 0%\n",
      "\tloss: 1.4728935626335442 \n",
      "\tval_loss: 6.26357102394104\n",
      "Epoch 601: Training done. Testing at 0%\n",
      "\tloss: 1.4570817542262375 \n",
      "\tval_loss: 6.264317035675049\n",
      "Epoch 602: Training done. Testing at 0%\n",
      "\tloss: 1.429095541127026 \n",
      "\tval_loss: 6.26005482673645\n",
      "Epoch 603: Training done. Testing at 0%\n",
      "\tloss: 1.4911877918057144 \n",
      "\tval_loss: 6.258404016494751\n",
      "Epoch 604: Training done. Testing at 0%\n",
      "\tloss: 1.3877989668399096 \n",
      "\tval_loss: 6.26056694984436\n",
      "Epoch 605: Training done. Testing at 0%\n",
      "\tloss: 1.6418479047715664 \n",
      "\tval_loss: 6.266470670700073\n",
      "Epoch 606: Training done. Testing at 0%\n",
      "\tloss: 1.5202631684951484 \n",
      "\tval_loss: 6.273096799850464\n",
      "Epoch 607: Training done. Testing at 0%\n",
      "\tloss: 1.7333625950850546 \n",
      "\tval_loss: 6.2784340381622314\n",
      "Epoch 608: Training done. Testing at 0%\n",
      "\tloss: 1.486355253495276 \n",
      "\tval_loss: 6.290970325469971\n",
      "Epoch 609: Training done. Testing at 0%\n",
      "\tloss: 1.5681753759272397 \n",
      "\tval_loss: 6.294126749038696\n",
      "Epoch 610: Training done. Testing at 0%\n",
      "\tloss: 1.4257189324125648 \n",
      "\tval_loss: 6.294560194015503\n",
      "Epoch 611: Training done. Testing at 0%\n",
      "\tloss: 1.3903144388459623 \n",
      "\tval_loss: 6.295106649398804\n",
      "Epoch 612: Training done. Testing at 0%\n",
      "\tloss: 1.4437251896597445 \n",
      "\tval_loss: 6.299489736557007\n",
      "Epoch 613: Training done. Testing at 0%\n",
      "\tloss: 1.564267577137798 \n",
      "\tval_loss: 6.302024602890015\n",
      "Epoch 614: Training done. Testing at 0%\n",
      "\tloss: 1.4613812523894012 \n",
      "\tval_loss: 6.296112298965454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615: Training done. Testing at 0%\n",
      "\tloss: 1.4755785935558379 \n",
      "\tval_loss: 6.29684042930603\n",
      "Epoch 616: Training done. Testing at 0%\n",
      "\tloss: 1.4009528560563922 \n",
      "\tval_loss: 6.3008036613464355\n",
      "Epoch 617: Training done. Testing at 0%\n",
      "\tloss: 1.4661552179604769 \n",
      "\tval_loss: 6.300292253494263\n",
      "Epoch 618: Training done. Testing at 0%\n",
      "\tloss: 1.3908508117310703 \n",
      "\tval_loss: 6.306809663772583\n",
      "Epoch 619: Training done. Testing at 0%\n",
      "\tloss: 1.4984652157872915 \n",
      "\tval_loss: 6.317328214645386\n",
      "Epoch 620: Training done. Testing at 0%\n",
      "\tloss: 1.336682460270822 \n",
      "\tval_loss: 6.316580057144165\n",
      "Epoch 621: Training done. Testing at 0%\n",
      "\tloss: 1.3878406973090023 \n",
      "\tval_loss: 6.315640211105347\n",
      "Epoch 622: Training done. Testing at 0%\n",
      "\tloss: 1.5002559376880527 \n",
      "\tval_loss: 6.322380781173706\n",
      "Epoch 623: Training done. Testing at 0%\n",
      "\tloss: 1.3758341846987605 \n",
      "\tval_loss: 6.330301523208618\n",
      "Epoch 624: Training done. Testing at 0%\n",
      "\tloss: 1.4795598946511745 \n",
      "\tval_loss: 6.327343225479126\n",
      "Epoch 625: Training done. Testing at 0%\n",
      "\tloss: 1.4770712619647384 \n",
      "\tval_loss: 6.330157041549683\n",
      "Epoch 626: Training done. Testing at 0%\n",
      "\tloss: 1.5975517705082893 \n",
      "\tval_loss: 6.329970359802246\n",
      "Epoch 627: Training done. Testing at 0%\n",
      "\tloss: 1.3310583331622183 \n",
      "\tval_loss: 6.333963632583618\n",
      "Epoch 628: Training done. Testing at 0%\n",
      "\tloss: 1.5212617181241512 \n",
      "\tval_loss: 6.336106538772583\n",
      "Epoch 629: Training done. Testing at 0%\n",
      "\tloss: 1.4343775799497962 \n",
      "\tval_loss: 6.332636117935181\n",
      "Epoch 630: Training done. Testing at 0%\n",
      "\tloss: 1.4190009799785912 \n",
      "\tval_loss: 6.334617376327515\n",
      "Epoch 631: Training done. Testing at 0%\n",
      "\tloss: 1.3028403674252331 \n",
      "\tval_loss: 6.343984365463257\n",
      "Epoch 632: Training done. Testing at 0%\n",
      "\tloss: 1.3840595786459744 \n",
      "\tval_loss: 6.347494125366211\n",
      "Epoch 633: Training done. Testing at 0%\n",
      "\tloss: 1.4281994188204408 \n",
      "\tval_loss: 6.354485750198364\n",
      "Epoch 634: Training done. Testing at 0%\n",
      "\tloss: 1.3522219089791179 \n",
      "\tval_loss: 6.35408878326416\n",
      "Epoch 635: Training done. Testing at 0%\n",
      "\tloss: 1.4374484261497855 \n",
      "\tval_loss: 6.353930711746216\n",
      "Epoch 636: Training done. Testing at 0%\n",
      "\tloss: 1.3543856819160283 \n",
      "\tval_loss: 6.359113454818726\n",
      "Epoch 637: Training done. Testing at 0%\n",
      "\tloss: 1.2967287236824632 \n",
      "\tval_loss: 6.362125396728516\n",
      "Epoch 638: Training done. Testing at 0%\n",
      "\tloss: 1.606044267769903 \n",
      "\tval_loss: 6.369168519973755\n",
      "Epoch 639: Training done. Testing at 0%\n",
      "\tloss: 1.6595834149047732 \n",
      "\tval_loss: 6.36691689491272\n",
      "Epoch 640: Training done. Testing at 0%\n",
      "\tloss: 1.5367459440603852 \n",
      "\tval_loss: 6.370135545730591\n",
      "Epoch 641: Training done. Testing at 0%\n",
      "\tloss: 1.2495339042507112 \n",
      "\tval_loss: 6.372964382171631\n",
      "Epoch 642: Training done. Testing at 0%\n",
      "\tloss: 1.4141848334111273 \n",
      "\tval_loss: 6.365247488021851\n",
      "Epoch 643: Training done. Testing at 0%\n",
      "\tloss: 1.373296670615673 \n",
      "\tval_loss: 6.367936849594116\n",
      "Epoch 644: Training done. Testing at 0%\n",
      "\tloss: 1.5376382442191243 \n",
      "\tval_loss: 6.365469932556152\n",
      "Epoch 645: Training done. Testing at 0%\n",
      "\tloss: 1.3576233459170908 \n",
      "\tval_loss: 6.361656904220581\n",
      "Epoch 646: Training done. Testing at 0%\n",
      "\tloss: 1.349190806504339 \n",
      "\tval_loss: 6.3623106479644775\n",
      "Epoch 647: Training done. Testing at 0%\n",
      "\tloss: 1.6333957072347403 \n",
      "\tval_loss: 6.3624444007873535\n",
      "Epoch 648: Training done. Testing at 0%\n",
      "\tloss: 1.4046866348944604 \n",
      "\tval_loss: 6.369431734085083\n",
      "Epoch 649: Training done. Testing at 0%\n",
      "\tloss: 1.3997348193079233 \n",
      "\tval_loss: 6.3778910636901855\n",
      "Epoch 650: Training done. Testing at 0%\n",
      "\tloss: 1.2924545691348612 \n",
      "\tval_loss: 6.3790647983551025\n",
      "Epoch 651: Training done. Testing at 0%\n",
      "\tloss: 1.231403959915042 \n",
      "\tval_loss: 6.389955997467041\n",
      "Epoch 652: Training done. Testing at 0%\n",
      "\tloss: 1.4240099098533392 \n",
      "\tval_loss: 6.395391225814819\n",
      "Epoch 653: Training done. Testing at 0%\n",
      "\tloss: 1.288016500417143 \n",
      "\tval_loss: 6.405431270599365\n",
      "Epoch 654: Training done. Testing at 0%\n",
      "\tloss: 1.2802881048992276 \n",
      "\tval_loss: 6.407716512680054\n",
      "Epoch 655: Training done. Testing at 0%\n",
      "\tloss: 1.4759035781025887 \n",
      "\tval_loss: 6.411921501159668\n",
      "Epoch 656: Training done. Testing at 0%\n",
      "\tloss: 1.3192300722002983 \n",
      "\tval_loss: 6.41165828704834\n",
      "Epoch 657: Training done. Testing at 0%\n",
      "\tloss: 1.2215995066799223 \n",
      "\tval_loss: 6.40761923789978\n",
      "Epoch 658: Training done. Testing at 0%\n",
      "\tloss: 1.306154013145715 \n",
      "\tval_loss: 6.409907341003418\n",
      "Epoch 659: Training done. Testing at 0%\n",
      "\tloss: 1.312851366121322 \n",
      "\tval_loss: 6.409832954406738\n",
      "Epoch 660: Training done. Testing at 0%\n",
      "\tloss: 1.281836437061429 \n",
      "\tval_loss: 6.410274267196655\n",
      "Epoch 661: Training done. Testing at 0%\n",
      "\tloss: 1.3729425081983209 \n",
      "\tval_loss: 6.419285774230957\n",
      "Epoch 662: Training done. Testing at 0%\n",
      "\tloss: 1.2183837927877903 \n",
      "\tval_loss: 6.422908544540405\n",
      "Epoch 663: Training done. Testing at 0%\n",
      "\tloss: 1.309724963735789 \n",
      "\tval_loss: 6.417037725448608\n",
      "Epoch 664: Training done. Testing at 0%\n",
      "\tloss: 1.22916816547513 \n",
      "\tval_loss: 6.420300722122192\n",
      "Epoch 665: Training done. Testing at 0%\n",
      "\tloss: 1.4703092062845826 \n",
      "\tval_loss: 6.414910554885864\n",
      "Epoch 666: Training done. Testing at 0%\n",
      "\tloss: 1.3044444033876061 \n",
      "\tval_loss: 6.4150049686431885\n",
      "Epoch 667: Training done. Testing at 0%\n",
      "\tloss: 1.3870212263427675 \n",
      "\tval_loss: 6.417117118835449\n",
      "Epoch 668: Training done. Testing at 0%\n",
      "\tloss: 1.2013857122510672 \n",
      "\tval_loss: 6.429998159408569\n",
      "Epoch 669: Training done. Testing at 0%\n",
      "\tloss: 1.244777036830783 \n",
      "\tval_loss: 6.435520648956299\n",
      "Epoch 670: Training done. Testing at 0%\n",
      "\tloss: 1.2577405697666109 \n",
      "\tval_loss: 6.444676637649536\n",
      "Epoch 671: Training done. Testing at 0%\n",
      "\tloss: 1.2530770227313042 \n",
      "\tval_loss: 6.452186822891235\n",
      "Epoch 672: Training done. Testing at 0%\n",
      "\tloss: 1.212988149607554 \n",
      "\tval_loss: 6.456611394882202\n",
      "Epoch 673: Training done. Testing at 0%\n",
      "\tloss: 1.3924955273978412 \n",
      "\tval_loss: 6.455840349197388\n",
      "Epoch 674: Training done. Testing at 0%\n",
      "\tloss: 1.384707150515169 \n",
      "\tval_loss: 6.451287031173706\n",
      "Epoch 675: Training done. Testing at 0%\n",
      "\tloss: 1.2634389521554112 \n",
      "\tval_loss: 6.442239761352539\n",
      "Epoch 676: Training done. Testing at 0%\n",
      "\tloss: 1.2193436603993177 \n",
      "\tval_loss: 6.4408814907073975\n",
      "Epoch 677: Training done. Testing at 0%\n",
      "\tloss: 1.222372769843787 \n",
      "\tval_loss: 6.447657823562622\n",
      "Epoch 678: Training done. Testing at 0%\n",
      "\tloss: 1.3352827331982553 \n",
      "\tval_loss: 6.450134038925171\n",
      "Epoch 679: Training done. Testing at 0%\n",
      "\tloss: 1.1967228697612882 \n",
      "\tval_loss: 6.4500954151153564\n",
      "Epoch 680: Training done. Testing at 0%\n",
      "\tloss: 1.212192318867892 \n",
      "\tval_loss: 6.460343599319458\n",
      "Epoch 681: Training done. Testing at 0%\n",
      "\tloss: 1.2181409723125398 \n",
      "\tval_loss: 6.460855722427368\n",
      "Epoch 682: Training done. Testing at 0%\n",
      "\tloss: 1.2575658485293388 \n",
      "\tval_loss: 6.456282377243042\n",
      "Epoch 683: Training done. Testing at 0%\n",
      "\tloss: 1.3750224341638386 \n",
      "\tval_loss: 6.459409475326538\n",
      "Epoch 684: Training done. Testing at 0%\n",
      "\tloss: 1.134402396157384 \n",
      "\tval_loss: 6.458555459976196\n",
      "Epoch 685: Training done. Testing at 0%\n",
      "\tloss: 1.1490884474478662 \n",
      "\tval_loss: 6.462862014770508\n",
      "Epoch 686: Training done. Testing at 0%\n",
      "\tloss: 1.2476037694141269 \n",
      "\tval_loss: 6.466951131820679\n",
      "Epoch 687: Training done. Testing at 0%\n",
      "\tloss: 1.3643231042660773 \n",
      "\tval_loss: 6.475761651992798\n",
      "Epoch 688: Training done. Testing at 0%\n",
      "\tloss: 1.1756126545369625 \n",
      "\tval_loss: 6.480649709701538\n",
      "Epoch 689: Training done. Testing at 0%\n",
      "\tloss: 1.3532197871245444 \n",
      "\tval_loss: 6.48284125328064\n",
      "Epoch 690: Training done. Testing at 0%\n",
      "\tloss: 1.1802139072678983 \n",
      "\tval_loss: 6.489392280578613\n",
      "Epoch 691: Training done. Testing at 0%\n",
      "\tloss: 1.1626608720980585 \n",
      "\tval_loss: 6.489962339401245\n",
      "Epoch 692: Training done. Testing at 0%\n",
      "\tloss: 1.1268784422427416 \n",
      "\tval_loss: 6.492394208908081\n",
      "Epoch 693: Training done. Testing at 0%\n",
      "\tloss: 1.1709572332911193 \n",
      "\tval_loss: 6.483736753463745\n",
      "Epoch 694: Training done. Testing at 0%\n",
      "\tloss: 1.2687193504534662 \n",
      "\tval_loss: 6.478677749633789\n",
      "Epoch 695: Training done. Testing at 0%\n",
      "\tloss: 1.2757916050031781 \n",
      "\tval_loss: 6.477657794952393\n",
      "Epoch 696: Training done. Testing at 0%\n",
      "\tloss: 1.1217670182231814 \n",
      "\tval_loss: 6.467285871505737\n",
      "Epoch 697: Training done. Testing at 0%\n",
      "\tloss: 1.1523703085258603 \n",
      "\tval_loss: 6.461198329925537\n",
      "Epoch 698: Training done. Testing at 0%\n",
      "\tloss: 1.1016265833750367 \n",
      "\tval_loss: 6.4689531326293945\n",
      "Epoch 699: Training done. Testing at 0%\n",
      "\tloss: 1.1796124004758894 \n",
      "\tval_loss: 6.478488922119141\n",
      "Epoch 700: Training done. Testing at 0%\n",
      "\tloss: 1.2099437867291272 \n",
      "\tval_loss: 6.488116264343262\n",
      "Epoch 701: Training done. Testing at 0%\n",
      "\tloss: 1.177368674427271 \n",
      "\tval_loss: 6.491856336593628\n",
      "Epoch 702: Training done. Testing at 0%\n",
      "\tloss: 1.06161357043311 \n",
      "\tval_loss: 6.486236572265625\n",
      "Epoch 703: Training done. Testing at 0%\n",
      "\tloss: 1.0742507046088576 \n",
      "\tval_loss: 6.490553140640259\n",
      "Epoch 704: Training done. Testing at 0%\n",
      "\tloss: 1.4311668118461967 \n",
      "\tval_loss: 6.491212606430054\n",
      "Epoch 705: Training done. Testing at 0%\n",
      "\tloss: 1.2964658080600202 \n",
      "\tval_loss: 6.491387128829956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 706: Training done. Testing at 0%\n",
      "\tloss: 1.1590843917801976 \n",
      "\tval_loss: 6.49906325340271\n",
      "Epoch 707: Training done. Testing at 0%\n",
      "\tloss: 1.3385034324601293 \n",
      "\tval_loss: 6.5081212520599365\n",
      "Epoch 708: Training done. Testing at 0%\n",
      "\tloss: 1.1376482946798205 \n",
      "\tval_loss: 6.518519639968872\n",
      "Epoch 709: Training done. Testing at 0%\n",
      "\tloss: 1.0893238852731884 \n",
      "\tval_loss: 6.5301432609558105\n",
      "Epoch 710: Training done. Testing at 0%\n",
      "\tloss: 1.1694641159847379 \n",
      "\tval_loss: 6.527734994888306\n",
      "Epoch 711: Training done. Testing at 0%\n",
      "\tloss: 1.0967252082191408 \n",
      "\tval_loss: 6.529945135116577\n",
      "Epoch 712: Training done. Testing at 0%\n",
      "\tloss: 1.2103545060381293 \n",
      "\tval_loss: 6.530905723571777\n",
      "Epoch 713: Training done. Testing at 0%\n",
      "\tloss: 1.1934269573539495 \n",
      "\tval_loss: 6.533470630645752\n",
      "Epoch 714: Training done. Testing at 0%\n",
      "\tloss: 1.287258598022163 \n",
      "\tval_loss: 6.5299272537231445\n",
      "Epoch 715: Training done. Testing at 0%\n",
      "\tloss: 1.1995809527579695 \n",
      "\tval_loss: 6.522888422012329\n",
      "Epoch 716: Training done. Testing at 0%\n",
      "\tloss: 1.0921900570392609 \n",
      "\tval_loss: 6.5238354206085205\n",
      "Epoch 717: Training done. Testing at 0%\n",
      "\tloss: 1.2187246130779386 \n",
      "\tval_loss: 6.525350332260132\n",
      "Epoch 718: Training done. Testing at 0%\n",
      "\tloss: 1.085519982734695 \n",
      "\tval_loss: 6.529167652130127\n",
      "Epoch 719: Training done. Testing at 0%\n",
      "\tloss: 1.1533319971058518 \n",
      "\tval_loss: 6.536447525024414\n",
      "Epoch 720: Training done. Testing at 0%\n",
      "\tloss: 1.0912050059996545 \n",
      "\tval_loss: 6.544414758682251\n",
      "Epoch 721: Training done. Testing at 0%\n",
      "\tloss: 1.0468567968346179 \n",
      "\tval_loss: 6.544677972793579\n",
      "Epoch 722: Training done. Testing at 0%\n",
      "\tloss: 1.1948894313536584 \n",
      "\tval_loss: 6.5523412227630615\n",
      "Epoch 723: Training done. Testing at 0%\n",
      "\tloss: 1.1792543707415462 \n",
      "\tval_loss: 6.551814794540405\n",
      "Epoch 724: Training done. Testing at 0%\n",
      "\tloss: 1.101304276380688 \n",
      "\tval_loss: 6.553928375244141\n",
      "Epoch 725: Training done. Testing at 0%\n",
      "\tloss: 1.1944338609464467 \n",
      "\tval_loss: 6.556504011154175\n",
      "Epoch 726: Training done. Testing at 0%\n",
      "\tloss: 1.0820675913710147 \n",
      "\tval_loss: 6.551227569580078\n",
      "Epoch 727: Training done. Testing at 0%\n",
      "\tloss: 1.3290521623566747 \n",
      "\tval_loss: 6.548314332962036\n",
      "Epoch 728: Training done. Testing at 0%\n",
      "\tloss: 1.2339948194567114 \n",
      "\tval_loss: 6.55634880065918\n",
      "Epoch 729: Training done. Testing at 0%\n",
      "\tloss: 1.3191482503898442 \n",
      "\tval_loss: 6.562497854232788\n",
      "Epoch 730: Training done. Testing at 0%\n",
      "\tloss: 1.1294670831412077 \n",
      "\tval_loss: 6.572369813919067\n",
      "Epoch 731: Training done. Testing at 0%\n",
      "\tloss: 1.0066669890657067 \n",
      "\tval_loss: 6.571335554122925\n",
      "Epoch 732: Training done. Testing at 0%\n",
      "\tloss: 1.2465375983156264 \n",
      "\tval_loss: 6.567800760269165\n",
      "Epoch 733: Training done. Testing at 0%\n",
      "\tloss: 1.1491741370409727 \n",
      "\tval_loss: 6.5652015209198\n",
      "Epoch 734: Training done. Testing at 0%\n",
      "\tloss: 1.0558712761849165 \n",
      "\tval_loss: 6.561290502548218\n",
      "Epoch 735: Training done. Testing at 0%\n",
      "\tloss: 1.0439516112674028 \n",
      "\tval_loss: 6.560649633407593\n",
      "Epoch 736: Training done. Testing at 0%\n",
      "\tloss: 0.9819118096493185 \n",
      "\tval_loss: 6.562103748321533\n",
      "Epoch 737: Training done. Testing at 0%\n",
      "\tloss: 1.1409673821181059 \n",
      "\tval_loss: 6.569178342819214\n",
      "Epoch 738: Training done. Testing at 0%\n",
      "\tloss: 1.1084337837528437 \n",
      "\tval_loss: 6.5665504932403564\n",
      "Epoch 739: Training done. Testing at 0%\n",
      "\tloss: 1.0358593580313027 \n",
      "\tval_loss: 6.571940660476685\n",
      "Epoch 740: Training done. Testing at 0%\n",
      "\tloss: 1.1047276535537094 \n",
      "\tval_loss: 6.5749733448028564\n",
      "Epoch 741: Training done. Testing at 0%\n",
      "\tloss: 1.0211617155000567 \n",
      "\tval_loss: 6.584415435791016\n",
      "Epoch 742: Training done. Testing at 0%\n",
      "\tloss: 1.122014002641663 \n",
      "\tval_loss: 6.582613706588745\n",
      "Epoch 743: Training done. Testing at 0%\n",
      "\tloss: 1.010828188387677 \n",
      "\tval_loss: 6.583772420883179\n",
      "Epoch 744: Training done. Testing at 0%\n",
      "\tloss: 1.2420380669645965 \n",
      "\tval_loss: 6.594567060470581\n",
      "Epoch 745: Training done. Testing at 0%\n",
      "\tloss: 0.993596580112353 \n",
      "\tval_loss: 6.599409341812134\n",
      "Epoch 746: Training done. Testing at 0%\n",
      "\tloss: 1.236576035618782 \n",
      "\tval_loss: 6.60342264175415\n",
      "Epoch 747: Training done. Testing at 0%\n",
      "\tloss: 1.070174349239096 \n",
      "\tval_loss: 6.610567331314087\n",
      "Epoch 748: Training done. Testing at 0%\n",
      "\tloss: 1.184191608801484 \n",
      "\tval_loss: 6.618281364440918\n",
      "Epoch 749: Training done. Testing at 0%\n",
      "\tloss: 1.0514960433356464 \n",
      "\tval_loss: 6.617515325546265\n",
      "Epoch 750: Training done. Testing at 0%\n",
      "\tloss: 1.0516762894112617 \n",
      "\tval_loss: 6.6203577518463135\n",
      "Epoch 751: Training done. Testing at 0%\n",
      "\tloss: 1.0842677177861333 \n",
      "\tval_loss: 6.620382070541382\n",
      "Epoch 752: Training done. Testing at 0%\n",
      "\tloss: 1.1299475254490972 \n",
      "\tval_loss: 6.623361825942993\n",
      "Epoch 753: Training done. Testing at 0%\n",
      "\tloss: 1.037728060502559 \n",
      "\tval_loss: 6.62976336479187\n",
      "Epoch 754: Training done. Testing at 0%\n",
      "\tloss: 1.1565431100316346 \n",
      "\tval_loss: 6.6263086795806885\n",
      "Epoch 755: Training done. Testing at 0%\n",
      "\tloss: 1.040177961345762 \n",
      "\tval_loss: 6.621179580688477\n",
      "Epoch 756: Training done. Testing at 0%\n",
      "\tloss: 1.1033820300363004 \n",
      "\tval_loss: 6.618759870529175\n",
      "Epoch 757: Training done. Testing at 0%\n",
      "\tloss: 0.9816967470105737 \n",
      "\tval_loss: 6.616397380828857\n",
      "Epoch 758: Training done. Testing at 0%\n",
      "\tloss: 0.9783604685217142 \n",
      "\tval_loss: 6.621170282363892\n",
      "Epoch 759: Training done. Testing at 0%\n",
      "\tloss: 1.0387930911965668 \n",
      "\tval_loss: 6.622740268707275\n",
      "Epoch 760: Training done. Testing at 0%\n",
      "\tloss: 0.9843144083861262 \n",
      "\tval_loss: 6.626055479049683\n",
      "Epoch 761: Training done. Testing at 0%\n",
      "\tloss: 1.1297304518520832 \n",
      "\tval_loss: 6.625962495803833\n",
      "Epoch 762: Training done. Testing at 0%\n",
      "\tloss: 0.9503063694573939 \n",
      "\tval_loss: 6.629350662231445\n",
      "Epoch 763: Training done. Testing at 0%\n",
      "\tloss: 1.0404077293351293 \n",
      "\tval_loss: 6.631298303604126\n",
      "Epoch 764: Training done. Testing at 0%\n",
      "\tloss: 0.9927691349294037 \n",
      "\tval_loss: 6.630695343017578\n",
      "Epoch 765: Training done. Testing at 0%\n",
      "\tloss: 1.0394578007981181 \n",
      "\tval_loss: 6.63360857963562\n",
      "Epoch 766: Training done. Testing at 0%\n",
      "\tloss: 1.162714321166277 \n",
      "\tval_loss: 6.635900974273682\n",
      "Epoch 767: Training done. Testing at 0%\n",
      "\tloss: 1.0054436412174255 \n",
      "\tval_loss: 6.64353346824646\n",
      "Epoch 768: Training done. Testing at 0%\n",
      "\tloss: 0.9500076642725617 \n",
      "\tval_loss: 6.648030996322632\n",
      "Epoch 769: Training done. Testing at 0%\n",
      "\tloss: 0.9361869413405657 \n",
      "\tval_loss: 6.652605772018433\n",
      "Epoch 770: Training done. Testing at 0%\n",
      "\tloss: 1.0249162591062486 \n",
      "\tval_loss: 6.656541109085083\n",
      "Epoch 771: Training done. Testing at 0%\n",
      "\tloss: 0.984761736355722 \n",
      "\tval_loss: 6.658189058303833\n",
      "Epoch 772: Training done. Testing at 0%\n",
      "\tloss: 1.4368099975399673 \n",
      "\tval_loss: 6.6664087772369385\n",
      "Epoch 773: Training done. Testing at 0%\n",
      "\tloss: 1.0436104990076274 \n",
      "\tval_loss: 6.671382665634155\n",
      "Epoch 774: Training done. Testing at 0%\n",
      "\tloss: 0.9683244770858437 \n",
      "\tval_loss: 6.680785417556763\n",
      "Epoch 775: Training done. Testing at 0%\n",
      "\tloss: 1.0842371797189116 \n",
      "\tval_loss: 6.675341606140137\n",
      "Epoch 776: Training done. Testing at 0%\n",
      "\tloss: 1.1279120719991624 \n",
      "\tval_loss: 6.678924322128296\n",
      "Epoch 777: Training done. Testing at 0%\n",
      "\tloss: 0.9038935331627727 \n",
      "\tval_loss: 6.682502031326294\n",
      "Epoch 778: Training done. Testing at 0%\n",
      "\tloss: 0.9326898409053683 \n",
      "\tval_loss: 6.6831793785095215\n",
      "Epoch 779: Training done. Testing at 0%\n",
      "\tloss: 0.9078512785490602 \n",
      "\tval_loss: 6.682491302490234\n",
      "Epoch 780: Training done. Testing at 0%\n",
      "\tloss: 0.9237238224595785 \n",
      "\tval_loss: 6.675947427749634\n",
      "Epoch 781: Training done. Testing at 0%\n",
      "\tloss: 0.9040635996498168 \n",
      "\tval_loss: 6.673821687698364\n",
      "Epoch 782: Training done. Testing at 0%\n",
      "\tloss: 0.9386602691374719 \n",
      "\tval_loss: 6.671130895614624\n",
      "Epoch 783: Training done. Testing at 0%\n",
      "\tloss: 0.9819792264606804 \n",
      "\tval_loss: 6.668780565261841\n",
      "Epoch 784: Training done. Testing at 0%\n",
      "\tloss: 0.9690163643099368 \n",
      "\tval_loss: 6.672755241394043\n",
      "Epoch 785: Training done. Testing at 0%\n",
      "\tloss: 0.862120424862951 \n",
      "\tval_loss: 6.676209211349487\n",
      "Epoch 786: Training done. Testing at 0%\n",
      "\tloss: 1.0572263030335307 \n",
      "\tval_loss: 6.677897930145264\n",
      "Epoch 787: Training done. Testing at 0%\n",
      "\tloss: 1.005743912421167 \n",
      "\tval_loss: 6.676896572113037\n",
      "Epoch 788: Training done. Testing at 0%\n",
      "\tloss: 0.9322695985902101 \n",
      "\tval_loss: 6.677448034286499\n",
      "Epoch 789: Training done. Testing at 0%\n",
      "\tloss: 0.9415625566616654 \n",
      "\tval_loss: 6.669176816940308\n",
      "Epoch 790: Training done. Testing at 0%\n",
      "\tloss: 0.869306828128174 \n",
      "\tval_loss: 6.67211651802063\n",
      "Epoch 791: Training done. Testing at 0%\n",
      "\tloss: 0.9661670119967312 \n",
      "\tval_loss: 6.68031907081604\n",
      "Epoch 792: Training done. Testing at 0%\n",
      "\tloss: 0.9221847120206803 \n",
      "\tval_loss: 6.68550968170166\n",
      "Epoch 793: Training done. Testing at 0%\n",
      "\tloss: 0.9950413550250232 \n",
      "\tval_loss: 6.692538499832153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 794: Training done. Testing at 0%\n",
      "\tloss: 1.0871238089166582 \n",
      "\tval_loss: 6.69731068611145\n",
      "Epoch 795: Training done. Testing at 0%\n",
      "\tloss: 0.8728219384793192 \n",
      "\tval_loss: 6.702932596206665\n",
      "Epoch 796: Training done. Testing at 0%\n",
      "\tloss: 0.9813394085504115 \n",
      "\tval_loss: 6.704437494277954\n",
      "Epoch 797: Training done. Testing at 0%\n",
      "\tloss: 0.9475173156242818 \n",
      "\tval_loss: 6.705540418624878\n",
      "Epoch 798: Training done. Testing at 0%\n",
      "\tloss: 0.8675471036694944 \n",
      "\tval_loss: 6.705181360244751\n",
      "Epoch 799: Training done. Testing at 0%\n",
      "\tloss: 0.9638756671920419 \n",
      "\tval_loss: 6.707234144210815\n",
      "Epoch 800: Training done. Testing at 0%\n",
      "\tloss: 1.0232166908681393 \n",
      "\tval_loss: 6.7072484493255615\n",
      "Epoch 801: Training done. Testing at 0%\n",
      "\tloss: 0.9227026230655611 \n",
      "\tval_loss: 6.71133828163147\n",
      "Epoch 802: Training done. Testing at 0%\n",
      "\tloss: 0.8706914021167904 \n",
      "\tval_loss: 6.714235067367554\n",
      "Epoch 803: Training done. Testing at 0%\n",
      "\tloss: 0.9964861331973225 \n",
      "\tval_loss: 6.717991590499878\n",
      "Epoch 804: Training done. Testing at 0%\n",
      "\tloss: 0.9445902244187891 \n",
      "\tval_loss: 6.71739935874939\n",
      "Epoch 805: Training done. Testing at 0%\n",
      "\tloss: 1.1710477541200817 \n",
      "\tval_loss: 6.710680246353149\n",
      "Epoch 806: Training done. Testing at 0%\n",
      "\tloss: 0.9123338058125228 \n",
      "\tval_loss: 6.715965986251831\n",
      "Epoch 807: Training done. Testing at 0%\n",
      "\tloss: 0.9136806109454483 \n",
      "\tval_loss: 6.725335121154785\n",
      "Epoch 808: Training done. Testing at 0%\n",
      "\tloss: 0.9070869542192668 \n",
      "\tval_loss: 6.730585813522339\n",
      "Epoch 809: Training done. Testing at 0%\n",
      "\tloss: 0.8850776811596006 \n",
      "\tval_loss: 6.732717275619507\n",
      "Epoch 810: Training done. Testing at 0%\n",
      "\tloss: 0.8702097591012716 \n",
      "\tval_loss: 6.7348952293396\n",
      "Epoch 811: Training done. Testing at 0%\n",
      "\tloss: 0.8833896017167717 \n",
      "\tval_loss: 6.7408225536346436\n",
      "Epoch 812: Training done. Testing at 0%\n",
      "\tloss: 0.8428902444429696 \n",
      "\tval_loss: 6.742748737335205\n",
      "Epoch 813: Training done. Testing at 0%\n",
      "\tloss: 1.016111773205921 \n",
      "\tval_loss: 6.748212575912476\n",
      "Epoch 814: Training done. Testing at 0%\n",
      "\tloss: 1.2145831261295825 \n",
      "\tval_loss: 6.751032114028931\n",
      "Epoch 815: Training done. Testing at 0%\n",
      "\tloss: 0.8618604836519808 \n",
      "\tval_loss: 6.754877328872681\n",
      "Epoch 816: Training done. Testing at 0%\n",
      "\tloss: 0.8199011408723891 \n",
      "\tval_loss: 6.754187107086182\n",
      "Epoch 817: Training done. Testing at 0%\n",
      "\tloss: 0.996923181694001 \n",
      "\tval_loss: 6.752438306808472\n",
      "Epoch 818: Training done. Testing at 0%\n",
      "\tloss: 0.8190109878778458 \n",
      "\tval_loss: 6.742823839187622\n",
      "Epoch 819: Training done. Testing at 0%\n",
      "\tloss: 0.8524543340317905 \n",
      "\tval_loss: 6.744478940963745\n",
      "Epoch 820: Training done. Testing at 0%\n",
      "\tloss: 0.8757460596971214 \n",
      "\tval_loss: 6.738904237747192\n",
      "Epoch 821: Training done. Testing at 0%\n",
      "\tloss: 0.852645396720618 \n",
      "\tval_loss: 6.738261938095093\n",
      "Epoch 822: Training done. Testing at 0%\n",
      "\tloss: 0.8902379479259253 \n",
      "\tval_loss: 6.7490394115448\n",
      "Epoch 823: Training done. Testing at 0%\n",
      "\tloss: 0.9177961084060371 \n",
      "\tval_loss: 6.754126310348511\n",
      "Epoch 824: Training done. Testing at 0%\n",
      "\tloss: 0.9290662445127964 \n",
      "\tval_loss: 6.765755653381348\n",
      "Epoch 825: Training done. Testing at 0%\n",
      "\tloss: 0.8566344708669931 \n",
      "\tval_loss: 6.769025802612305\n",
      "Epoch 826: Training done. Testing at 0%\n",
      "\tloss: 1.0253060082904994 \n",
      "\tval_loss: 6.774671316146851\n",
      "Epoch 827: Training done. Testing at 0%\n",
      "\tloss: 0.8648220158647746 \n",
      "\tval_loss: 6.778610944747925\n",
      "Epoch 828: Training done. Testing at 0%\n",
      "\tloss: 0.8051253010053188 \n",
      "\tval_loss: 6.7828123569488525\n",
      "Epoch 829: Training done. Testing at 0%\n",
      "\tloss: 0.9589542411267757 \n",
      "\tval_loss: 6.782679319381714\n",
      "Epoch 830: Training done. Testing at 0%\n",
      "\tloss: 0.8467114777304232 \n",
      "\tval_loss: 6.779787540435791\n",
      "Epoch 831: Training done. Testing at 0%\n",
      "\tloss: 0.8215032231528312 \n",
      "\tval_loss: 6.777385711669922\n",
      "Epoch 832: Training done. Testing at 0%\n",
      "\tloss: 0.8672917298972607 \n",
      "\tval_loss: 6.768671751022339\n",
      "Epoch 833: Training done. Testing at 0%\n",
      "\tloss: 0.7875360967591405 \n",
      "\tval_loss: 6.760772466659546\n",
      "Epoch 834: Training done. Testing at 0%\n",
      "\tloss: 0.8762141070328653 \n",
      "\tval_loss: 6.763646364212036\n",
      "Epoch 835: Training done. Testing at 0%\n",
      "\tloss: 0.9724549101665616 \n",
      "\tval_loss: 6.7671825885772705\n",
      "Epoch 836: Training done. Testing at 0%\n",
      "\tloss: 0.8490892611443996 \n",
      "\tval_loss: 6.762208700180054\n",
      "Epoch 837: Training done. Testing at 0%\n",
      "\tloss: 0.9284528095740825 \n",
      "\tval_loss: 6.754242181777954\n",
      "Epoch 838: Training done. Testing at 0%\n",
      "\tloss: 0.8464626925997436 \n",
      "\tval_loss: 6.761723756790161\n",
      "Epoch 839: Training done. Testing at 0%\n",
      "\tloss: 0.9016318621579558 \n",
      "\tval_loss: 6.77424430847168\n",
      "Epoch 840: Training done. Testing at 0%\n",
      "\tloss: 0.8441672252956778 \n",
      "\tval_loss: 6.778192520141602\n",
      "Epoch 841: Training done. Testing at 0%\n",
      "\tloss: 0.8369934672955424 \n",
      "\tval_loss: 6.780764579772949\n",
      "Epoch 842: Training done. Testing at 0%\n",
      "\tloss: 0.8484182376414537 \n",
      "\tval_loss: 6.787066698074341\n",
      "Epoch 843: Training done. Testing at 0%\n",
      "\tloss: 0.8333276659250259 \n",
      "\tval_loss: 6.790308237075806\n",
      "Epoch 844: Training done. Testing at 0%\n",
      "\tloss: 1.281868142541498 \n",
      "\tval_loss: 6.7868263721466064\n",
      "Epoch 845: Training done. Testing at 0%\n",
      "\tloss: 0.7717479411512613 \n",
      "\tval_loss: 6.784736394882202\n",
      "Epoch 846: Training done. Testing at 0%\n",
      "\tloss: 0.9434440941549838 \n",
      "\tval_loss: 6.784011125564575\n",
      "Epoch 847: Training done. Testing at 0%\n",
      "\tloss: 0.9478640588931739 \n",
      "\tval_loss: 6.78672194480896\n",
      "Epoch 848: Training done. Testing at 0%\n",
      "\tloss: 0.8704842559527606 \n",
      "\tval_loss: 6.786071062088013\n",
      "Epoch 849: Training done. Testing at 0%\n",
      "\tloss: 0.7771507068537176 \n",
      "\tval_loss: 6.788573741912842\n",
      "Epoch 850: Training done. Testing at 0%\n",
      "\tloss: 0.8903045342303813 \n",
      "\tval_loss: 6.789851903915405\n",
      "Epoch 851: Training done. Testing at 0%\n",
      "\tloss: 0.7699582811910659 \n",
      "\tval_loss: 6.7904956340789795\n",
      "Epoch 852: Training done. Testing at 0%\n",
      "\tloss: 0.8052186942659318 \n",
      "\tval_loss: 6.796874284744263\n",
      "Epoch 853: Training done. Testing at 0%\n",
      "\tloss: 0.7766754720360041 \n",
      "\tval_loss: 6.802180051803589\n",
      "Epoch 854: Training done. Testing at 0%\n",
      "\tloss: 0.9000271977856755 \n",
      "\tval_loss: 6.800072908401489\n",
      "Epoch 855: Training done. Testing at 0%\n",
      "\tloss: 0.8011376583017409 \n",
      "\tval_loss: 6.794841527938843\n",
      "Epoch 856: Training done. Testing at 0%\n",
      "\tloss: 0.8168410528451204 \n",
      "\tval_loss: 6.79449462890625\n",
      "Epoch 857: Training done. Testing at 0%\n",
      "\tloss: 0.7835681184660643 \n",
      "\tval_loss: 6.7962806224823\n",
      "Epoch 858: Training done. Testing at 0%\n",
      "\tloss: 0.9082669035997242 \n",
      "\tval_loss: 6.7928688526153564\n",
      "Epoch 859: Training done. Testing at 0%\n",
      "\tloss: 0.835492898710072 \n",
      "\tval_loss: 6.807296991348267\n",
      "Epoch 860: Training done. Testing at 0%\n",
      "\tloss: 0.7988758212886751 \n",
      "\tval_loss: 6.810004234313965\n",
      "Epoch 861: Training done. Testing at 0%\n",
      "\tloss: 0.8471554724965245 \n",
      "\tval_loss: 6.812721490859985\n",
      "Epoch 862: Training done. Testing at 0%\n",
      "\tloss: 0.8842502448242158 \n",
      "\tval_loss: 6.819414854049683\n",
      "Epoch 863: Training done. Testing at 0%\n",
      "\tloss: 0.7866749332752079 \n",
      "\tval_loss: 6.819228172302246\n",
      "Epoch 864: Training done. Testing at 0%\n",
      "\tloss: 0.9817874294240028 \n",
      "\tval_loss: 6.823655605316162\n",
      "Epoch 865: Training done. Testing at 0%\n",
      "\tloss: 0.7409654785878956 \n",
      "\tval_loss: 6.822438955307007\n",
      "Epoch 866: Training done. Testing at 0%\n",
      "\tloss: 0.906401717569679 \n",
      "\tval_loss: 6.826809883117676\n",
      "Epoch 867: Training done. Testing at 0%\n",
      "\tloss: 0.7548876460641623 \n",
      "\tval_loss: 6.831966876983643\n",
      "Epoch 868: Training done. Testing at 0%\n",
      "\tloss: 0.8125792075879872 \n",
      "\tval_loss: 6.8360981941223145\n",
      "Epoch 869: Training done. Testing at 0%\n",
      "\tloss: 1.0248054577969015 \n",
      "\tval_loss: 6.833895921707153\n",
      "Epoch 870: Training done. Testing at 0%\n",
      "\tloss: 0.7503355566877872 \n",
      "\tval_loss: 6.838682413101196\n",
      "Epoch 871: Training done. Testing at 0%\n",
      "\tloss: 0.7872166300658137 \n",
      "\tval_loss: 6.840469121932983\n",
      "Epoch 872: Training done. Testing at 0%\n",
      "\tloss: 0.875254712998867 \n",
      "\tval_loss: 6.839848279953003\n",
      "Epoch 873: Training done. Testing at 0%\n",
      "\tloss: 0.7888347040861845 \n",
      "\tval_loss: 6.8344316482543945\n",
      "Epoch 874: Training done. Testing at 0%\n",
      "\tloss: 0.7879444323480129 \n",
      "\tval_loss: 6.8351733684539795\n",
      "Epoch 875: Training done. Testing at 0%\n",
      "\tloss: 0.7633359686005861 \n",
      "\tval_loss: 6.833299398422241\n",
      "Epoch 876: Training done. Testing at 0%\n",
      "\tloss: 0.8056282345205545 \n",
      "\tval_loss: 6.835833549499512\n",
      "Epoch 877: Training done. Testing at 0%\n",
      "\tloss: 0.8143377469386905 \n",
      "\tval_loss: 6.833850145339966\n",
      "Epoch 878: Training done. Testing at 0%\n",
      "\tloss: 0.7395699894987047 \n",
      "\tval_loss: 6.837554454803467\n",
      "Epoch 879: Training done. Testing at 0%\n",
      "\tloss: 0.8864729246124625 \n",
      "\tval_loss: 6.839229583740234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880: Training done. Testing at 0%\n",
      "\tloss: 0.8331449776887894 \n",
      "\tval_loss: 6.844335079193115\n",
      "Epoch 881: Training done. Testing at 0%\n",
      "\tloss: 0.7812369612511247 \n",
      "\tval_loss: 6.848879814147949\n",
      "Epoch 882: Training done. Testing at 0%\n",
      "\tloss: 0.8051454266533256 \n",
      "\tval_loss: 6.852624177932739\n",
      "Epoch 883: Training done. Testing at 0%\n",
      "\tloss: 0.750313678290695 \n",
      "\tval_loss: 6.8611743450164795\n",
      "Epoch 884: Training done. Testing at 0%\n",
      "\tloss: 0.75173759018071 \n",
      "\tval_loss: 6.864438772201538\n",
      "Epoch 885: Training done. Testing at 0%\n",
      "\tloss: 0.758768949424848 \n",
      "\tval_loss: 6.8701536655426025\n",
      "Epoch 886: Training done. Testing at 0%\n",
      "\tloss: 0.7318265177309513 \n",
      "\tval_loss: 6.869868278503418\n",
      "Epoch 887: Training done. Testing at 0%\n",
      "\tloss: 0.794995759613812 \n",
      "\tval_loss: 6.87250542640686\n",
      "Epoch 888: Training done. Testing at 0%\n",
      "\tloss: 0.762935642618686 \n",
      "\tval_loss: 6.881920337677002\n",
      "Epoch 889: Training done. Testing at 0%\n",
      "\tloss: 0.8915914129465818 \n",
      "\tval_loss: 6.882949590682983\n",
      "Epoch 890: Training done. Testing at 0%\n",
      "\tloss: 0.7806196878664196 \n",
      "\tval_loss: 6.882615566253662\n",
      "Epoch 891: Training done. Testing at 0%\n",
      "\tloss: 0.8149372558109462 \n",
      "\tval_loss: 6.88145899772644\n",
      "Epoch 892: Training done. Testing at 0%\n",
      "\tloss: 0.7703122275415808 \n",
      "\tval_loss: 6.875433683395386\n",
      "Epoch 893: Training done. Testing at 0%\n",
      "\tloss: 0.7414987657684833 \n",
      "\tval_loss: 6.879208087921143\n",
      "Epoch 894: Training done. Testing at 0%\n",
      "\tloss: 0.7296695858240128 \n",
      "\tval_loss: 6.8790671825408936\n",
      "Epoch 895: Training done. Testing at 0%\n",
      "\tloss: 0.77301244600676 \n",
      "\tval_loss: 6.8843207359313965\n",
      "Epoch 896: Training done. Testing at 0%\n",
      "\tloss: 0.8211978222243488 \n",
      "\tval_loss: 6.884968042373657\n",
      "Epoch 897: Training done. Testing at 0%\n",
      "\tloss: 0.8242158871144056 \n",
      "\tval_loss: 6.88933539390564\n",
      "Epoch 898: Training done. Testing at 0%\n",
      "\tloss: 0.7850574562326074 \n",
      "\tval_loss: 6.878821134567261\n",
      "Epoch 899: Training done. Testing at 0%\n",
      "\tloss: 0.8361363301519305 \n",
      "\tval_loss: 6.878844738006592\n",
      "Epoch 900: Training done. Testing at 0%\n",
      "\tloss: 0.7205973104573786 \n",
      "\tval_loss: 6.881391763687134\n",
      "Epoch 901: Training done. Testing at 0%\n",
      "\tloss: 0.7465072830673307 \n",
      "\tval_loss: 6.881182909011841\n",
      "Epoch 902: Training done. Testing at 0%\n",
      "\tloss: 0.7654137033969164 \n",
      "\tval_loss: 6.88550877571106\n",
      "Epoch 903: Training done. Testing at 0%\n",
      "\tloss: 0.7140054295305163 \n",
      "\tval_loss: 6.885655403137207\n",
      "Epoch 904: Training done. Testing at 0%\n",
      "\tloss: 0.7702641424257308 \n",
      "\tval_loss: 6.885934352874756\n",
      "Epoch 905: Training done. Testing at 0%\n",
      "\tloss: 0.718690904090181 \n",
      "\tval_loss: 6.891848802566528\n",
      "Epoch 906: Training done. Testing at 0%\n",
      "\tloss: 0.7837675088085234 \n",
      "\tval_loss: 6.898151636123657\n",
      "Epoch 907: Training done. Testing at 0%\n",
      "\tloss: 0.7893122134264559 \n",
      "\tval_loss: 6.906955718994141\n",
      "Epoch 908: Training done. Testing at 0%\n",
      "\tloss: 0.6871021473780274 \n",
      "\tval_loss: 6.910891771316528\n",
      "Epoch 909: Training done. Testing at 0%\n",
      "\tloss: 0.6707310663769022 \n",
      "\tval_loss: 6.9106221199035645\n",
      "Epoch 910: Training done. Testing at 0%\n",
      "\tloss: 0.6853203603532165 \n",
      "\tval_loss: 6.907599449157715\n",
      "Epoch 911: Training done. Testing at 0%\n",
      "\tloss: 0.6868665050715208 \n",
      "\tval_loss: 6.906683921813965\n",
      "Epoch 912: Training done. Testing at 0%\n",
      "\tloss: 0.7357971430756152 \n",
      "\tval_loss: 6.906008005142212\n",
      "Epoch 913: Training done. Testing at 0%\n",
      "\tloss: 0.7100905620027333 \n",
      "\tval_loss: 6.904382944107056\n",
      "Epoch 914: Training done. Testing at 0%\n",
      "\tloss: 0.7397264051251113 \n",
      "\tval_loss: 6.911651372909546\n",
      "Epoch 915: Training done. Testing at 0%\n",
      "\tloss: 0.6790613499470055 \n",
      "\tval_loss: 6.913189172744751\n",
      "Epoch 916: Training done. Testing at 0%\n",
      "\tloss: 0.7677391706965864 \n",
      "\tval_loss: 6.917039394378662\n",
      "Epoch 917: Training done. Testing at 0%\n",
      "\tloss: 0.7589147547259927 \n",
      "\tval_loss: 6.914653301239014\n",
      "Epoch 918: Training done. Testing at 0%\n",
      "\tloss: 0.706491676857695 \n",
      "\tval_loss: 6.917942762374878\n",
      "Epoch 919: Training done. Testing at 0%\n",
      "\tloss: 0.7844644659198821 \n",
      "\tval_loss: 6.923407316207886\n",
      "Epoch 920: Training done. Testing at 0%\n",
      "\tloss: 0.7554874354973435 \n",
      "\tval_loss: 6.924327850341797\n",
      "Epoch 921: Training done. Testing at 0%\n",
      "\tloss: 0.8803705361206084 \n",
      "\tval_loss: 6.921294450759888\n",
      "Epoch 922: Training done. Testing at 0%\n",
      "\tloss: 0.8129397924058139 \n",
      "\tval_loss: 6.9233479499816895\n",
      "Epoch 923: Training done. Testing at 0%\n",
      "\tloss: 0.7278944991994649 \n",
      "\tval_loss: 6.927178859710693\n",
      "Epoch 924: Training done. Testing at 0%\n",
      "\tloss: 0.7273415650706738 \n",
      "\tval_loss: 6.933018207550049\n",
      "Epoch 925: Training done. Testing at 0%\n",
      "\tloss: 1.0225093583576381 \n",
      "\tval_loss: 6.938183784484863\n",
      "Epoch 926: Training done. Testing at 0%\n",
      "\tloss: 0.8660299230832607 \n",
      "\tval_loss: 6.944156169891357\n",
      "Epoch 927: Training done. Testing at 0%\n",
      "\tloss: 0.7850735355168581 \n",
      "\tval_loss: 6.952823638916016\n",
      "Epoch 928: Training done. Testing at 0%\n",
      "\tloss: 0.7305396194569767 \n",
      "\tval_loss: 6.958024978637695\n",
      "Epoch 929: Training done. Testing at 0%\n",
      "\tloss: 0.7229385292157531 \n",
      "\tval_loss: 6.963380813598633\n",
      "Epoch 930: Training done. Testing at 0%\n",
      "\tloss: 0.8494234902318567 \n",
      "\tval_loss: 6.964400768280029\n",
      "Epoch 931: Training done. Testing at 0%\n",
      "\tloss: 0.7409105936530977 \n",
      "\tval_loss: 6.968076467514038\n",
      "Epoch 932: Training done. Testing at 0%\n",
      "\tloss: 0.6564515943173319 \n",
      "\tval_loss: 6.9649529457092285\n",
      "Epoch 933: Training done. Testing at 0%\n",
      "\tloss: 0.6877442765980959 \n",
      "\tval_loss: 6.970320224761963\n",
      "Epoch 934: Training done. Testing at 0%\n",
      "\tloss: 0.6864978556986898 \n",
      "\tval_loss: 6.970986843109131\n",
      "Epoch 935: Training done. Testing at 0%\n",
      "\tloss: 0.71181530947797 \n",
      "\tval_loss: 6.969677925109863\n",
      "Epoch 936: Training done. Testing at 0%\n",
      "\tloss: 0.69194627890829 \n",
      "\tval_loss: 6.96653151512146\n",
      "Epoch 937: Training done. Testing at 0%\n",
      "\tloss: 0.788642852101475 \n",
      "\tval_loss: 6.966083765029907\n",
      "Epoch 938: Training done. Testing at 0%\n",
      "\tloss: 0.6607879672665149 \n",
      "\tval_loss: 6.964716196060181\n",
      "Epoch 939: Training done. Testing at 0%\n",
      "\tloss: 0.6947369053959846 \n",
      "\tval_loss: 6.962437391281128\n",
      "Epoch 940: Training done. Testing at 0%\n",
      "\tloss: 0.6518081463873386 \n",
      "\tval_loss: 6.965869903564453\n",
      "Epoch 941: Training done. Testing at 0%\n",
      "\tloss: 0.6962991484906524 \n",
      "\tval_loss: 6.962213516235352\n",
      "Epoch 942: Training done. Testing at 0%\n",
      "\tloss: 0.7712157263886184 \n",
      "\tval_loss: 6.960712194442749\n",
      "Epoch 943: Training done. Testing at 0%\n",
      "\tloss: 0.6581042566103861 \n",
      "\tval_loss: 6.95638632774353\n",
      "Epoch 944: Training done. Testing at 0%\n",
      "\tloss: 0.6246048707980663 \n",
      "\tval_loss: 6.953994512557983\n",
      "Epoch 945: Training done. Testing at 0%\n",
      "\tloss: 0.6842613574117422 \n",
      "\tval_loss: 6.953546762466431\n",
      "Epoch 946: Training done. Testing at 0%\n",
      "\tloss: 0.7743672323413193 \n",
      "\tval_loss: 6.954284906387329\n",
      "Epoch 947: Training done. Testing at 0%\n",
      "\tloss: 0.7303912308998406 \n",
      "\tval_loss: 6.965581655502319\n",
      "Epoch 948: Training done. Testing at 0%\n",
      "\tloss: 0.707598889246583 \n",
      "\tval_loss: 6.969044923782349\n",
      "Epoch 949: Training done. Testing at 0%\n",
      "\tloss: 0.7750682504847646 \n",
      "\tval_loss: 6.972398042678833\n",
      "Epoch 950: Training done. Testing at 0%\n",
      "\tloss: 0.6424268232658505 \n",
      "\tval_loss: 6.968290328979492\n",
      "Epoch 951: Training done. Testing at 0%\n",
      "\tloss: 0.6874971478246152 \n",
      "\tval_loss: 6.971840858459473\n",
      "Epoch 952: Training done. Testing at 0%\n",
      "\tloss: 0.7688006958924234 \n",
      "\tval_loss: 6.9779441356658936\n",
      "Epoch 953: Training done. Testing at 0%\n",
      "\tloss: 0.9127772683277726 \n",
      "\tval_loss: 6.99317479133606\n",
      "Epoch 954: Training done. Testing at 0%\n",
      "\tloss: 0.7167118854122236 \n",
      "\tval_loss: 7.000503301620483\n",
      "Epoch 955: Training done. Testing at 0%\n",
      "\tloss: 0.6909259872045368 \n",
      "\tval_loss: 7.0059449672698975\n",
      "Epoch 956: Training done. Testing at 0%\n",
      "\tloss: 0.9032488805241883 \n",
      "\tval_loss: 7.007956266403198\n",
      "Epoch 957: Training done. Testing at 0%\n",
      "\tloss: 0.6269452134147286 \n",
      "\tval_loss: 7.016098737716675\n",
      "Epoch 958: Training done. Testing at 0%\n",
      "\tloss: 0.6463437902275473 \n",
      "\tval_loss: 7.01835823059082\n",
      "Epoch 959: Training done. Testing at 0%\n",
      "\tloss: 0.6991336946375668 \n",
      "\tval_loss: 7.020971059799194\n",
      "Epoch 960: Training done. Testing at 0%\n",
      "\tloss: 0.6180403619073331 \n",
      "\tval_loss: 7.022496700286865\n",
      "Epoch 961: Training done. Testing at 0%\n",
      "\tloss: 0.6465443286579102 \n",
      "\tval_loss: 7.018639326095581\n",
      "Epoch 962: Training done. Testing at 0%\n",
      "\tloss: 0.6548478528857231 \n",
      "\tval_loss: 7.006643772125244\n",
      "Epoch 963: Training done. Testing at 0%\n",
      "\tloss: 0.8190765287727118 \n",
      "\tval_loss: 6.99846339225769\n",
      "Epoch 964: Training done. Testing at 0%\n",
      "\tloss: 0.6256325875874609 \n",
      "\tval_loss: 6.994946479797363\n",
      "Epoch 965: Training done. Testing at 0%\n",
      "\tloss: 0.6765137694310397 \n",
      "\tval_loss: 6.99700927734375\n",
      "Epoch 966: Training done. Testing at 0%\n",
      "\tloss: 0.7620588475838304 \n",
      "\tval_loss: 6.9997758865356445\n",
      "Epoch 967: Training done. Testing at 0%\n",
      "\tloss: 0.695872952695936 \n",
      "\tval_loss: 7.004676103591919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 968: Training done. Testing at 0%\n",
      "\tloss: 0.7288892904762179 \n",
      "\tval_loss: 7.0101234912872314\n",
      "Epoch 969: Training done. Testing at 0%\n",
      "\tloss: 0.6207748642191291 \n",
      "\tval_loss: 7.014218330383301\n",
      "Epoch 970: Training done. Testing at 0%\n",
      "\tloss: 0.8194397687911987 \n",
      "\tval_loss: 7.0116870403289795\n",
      "Epoch 971: Training done. Testing at 0%\n",
      "\tloss: 0.641215851996094 \n",
      "\tval_loss: 7.006657361984253\n",
      "Epoch 972: Training done. Testing at 0%\n",
      "\tloss: 0.654573364648968 \n",
      "\tval_loss: 7.000863075256348\n",
      "Epoch 973: Training done. Testing at 0%\n",
      "\tloss: 0.6131839137524366 \n",
      "\tval_loss: 7.004878520965576\n",
      "Epoch 974: Training done. Testing at 0%\n",
      "\tloss: 0.7727744451258332 \n",
      "\tval_loss: 7.011142730712891\n",
      "Epoch 975: Training done. Testing at 0%\n",
      "\tloss: 0.6700717308558524 \n",
      "\tval_loss: 7.020161390304565\n",
      "Epoch 976: Training done. Testing at 0%\n",
      "\tloss: 0.6626002606935799 \n",
      "\tval_loss: 7.018829584121704\n",
      "Epoch 977: Training done. Testing at 0%\n",
      "\tloss: 0.666986306430772 \n",
      "\tval_loss: 7.0220654010772705\n",
      "Epoch 978: Training done. Testing at 0%\n",
      "\tloss: 0.7344897948205471 \n",
      "\tval_loss: 7.023188352584839\n",
      "Epoch 979: Training done. Testing at 0%\n",
      "\tloss: 0.6538701239041984 \n",
      "\tval_loss: 7.029828786849976\n",
      "Epoch 980: Training done. Testing at 0%\n",
      "\tloss: 0.6248692381195724 \n",
      "\tval_loss: 7.032543897628784\n",
      "Epoch 981: Training done. Testing at 0%\n",
      "\tloss: 0.6337903804378584 \n",
      "\tval_loss: 7.032163381576538\n",
      "Epoch 982: Training done. Testing at 0%\n",
      "\tloss: 0.6069045715266839 \n",
      "\tval_loss: 7.0348005294799805\n",
      "Epoch 983: Training done. Testing at 0%\n",
      "\tloss: 0.6380991670303047 \n",
      "\tval_loss: 7.034269094467163\n",
      "Epoch 984: Training done. Testing at 0%\n",
      "\tloss: 0.7528178803622723 \n",
      "\tval_loss: 7.029350280761719\n",
      "Epoch 985: Training done. Testing at 0%\n",
      "\tloss: 0.6415539219742641 \n",
      "\tval_loss: 7.030383825302124\n",
      "Epoch 986: Training done. Testing at 0%\n",
      "\tloss: 0.6593231839360669 \n",
      "\tval_loss: 7.028762340545654\n",
      "Epoch 987: Training done. Testing at 0%\n",
      "\tloss: 0.627501365612261 \n",
      "\tval_loss: 7.03471827507019\n",
      "Epoch 988: Training done. Testing at 0%\n",
      "\tloss: 0.7266381464432925 \n",
      "\tval_loss: 7.047293186187744\n",
      "Epoch 989: Training done. Testing at 0%\n",
      "\tloss: 0.6309190595056862 \n",
      "\tval_loss: 7.054270505905151\n",
      "Epoch 990: Training done. Testing at 0%\n",
      "\tloss: 0.6297373620327562 \n",
      "\tval_loss: 7.058733701705933\n",
      "Epoch 991: Training done. Testing at 0%\n",
      "\tloss: 0.7035555528709665 \n",
      "\tval_loss: 7.060145616531372\n",
      "Epoch 992: Training done. Testing at 0%\n",
      "\tloss: 0.6102139635477215 \n",
      "\tval_loss: 7.0628578662872314\n",
      "Epoch 993: Training done. Testing at 0%\n",
      "\tloss: 0.6098961995448917 \n",
      "\tval_loss: 7.063894271850586\n",
      "Epoch 994: Training done. Testing at 0%\n",
      "\tloss: 0.6055559697560966 \n",
      "\tval_loss: 7.0592429637908936\n",
      "Epoch 995: Training done. Testing at 0%\n",
      "\tloss: 0.6855372870340943 \n",
      "\tval_loss: 7.054244756698608\n",
      "Epoch 996: Training done. Testing at 0%\n",
      "\tloss: 0.6687833953183144 \n",
      "\tval_loss: 7.037730932235718\n",
      "Epoch 997: Training done. Testing at 0%\n",
      "\tloss: 0.7481272285804152 \n",
      "\tval_loss: 7.041827917098999\n",
      "Epoch 998: Training done. Testing at 0%\n",
      "\tloss: 0.6818731140810996 \n",
      "\tval_loss: 7.0475099086761475\n",
      "Epoch 999: Training done. Testing at 0%\n",
      "\tloss: 0.5953589758137241 \n",
      "\tval_loss: 7.0583038330078125\n",
      "Epoch 1000: Training done. Testing at 0%\n",
      "\tloss: 0.6708125807344913 \n",
      "\tval_loss: 7.064484357833862\n"
     ]
    }
   ],
   "source": [
    "best_loss = float(\"inf\")\n",
    "best_classical_model = copy.deepcopy(basic_architecture.state_dict())\n",
    "loss_history_classical = []\n",
    "val_loss_history_classical = []\n",
    "basic_confusion_history = []\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    \n",
    "    tracking_loss = 0.0\n",
    "    \n",
    "    print(\"Epoch \"+str(epoch), end=\"\\r\")\n",
    "    \n",
    "    for batch_id, (data, labels) in enumerate(train_dataloader):\n",
    "        #reseting optimizer\n",
    "        opti_basic.zero_grad()\n",
    "        \n",
    "        #Adding noise to entry\n",
    "        data = data + (torch.rand((data.shape[0], data.shape[1])) - 0.5) * noise_magnitude\n",
    "        #Moving data and labels to GPU if needed\n",
    "        \n",
    "        #Performing inference\n",
    "        predictions = basic_architecture(data)\n",
    "        \n",
    "        #Computing loss\n",
    "        loss = criterion(predictions, labels.view(-1, 2))\n",
    "        #Backpropagate\n",
    "        loss.backward()\n",
    "        #Update optimizer\n",
    "        opti_basic.step()\n",
    "\n",
    "        #Adding loss\n",
    "        tracking_loss += loss.item() * len(labels)\n",
    "        print(\"Epoch \"+str(epoch)+\": Training at \"+str(int(batch_id/len(train_dataloader)*100))+\"%\", end=\"\\r\")\n",
    "        \n",
    "    loss_history_classical.append(tracking_loss / len(train_dataloader))\n",
    "    \n",
    "    tracking_val_loss = 0.0\n",
    "    \n",
    "    #Since we train, there is no need of keep track of the gradients. This speeds up the training process.\n",
    "    with torch.no_grad():\n",
    "        true_labels = []\n",
    "        basic_pred = []\n",
    "        for batch_id, (data, labels) in enumerate(test_dataloader):\n",
    "            \n",
    "            #Moving data and labels to GPU if needed\n",
    "            true_labels = true_labels + labels.tolist()\n",
    "\n",
    "            #Performing inference\n",
    "            predictions = basic_architecture(data)\n",
    "\n",
    "            #Computing loss\n",
    "            loss = criterion(predictions, labels)\n",
    "            base_predictions = predictions.detach()\n",
    "            base_predictions = torch.where(base_predictions > 0.5,\n",
    "                                           torch.ones_like(base_predictions),\n",
    "                                           torch.zeros_like(base_predictions)).tolist()\n",
    "            basic_pred = basic_pred + base_predictions\n",
    "\n",
    "            #Adding loss\n",
    "            tracking_val_loss += loss.item() * len(labels)\n",
    "            print(\"Epoch \"+str(epoch)+\": Training done. Testing at \"+str(int(batch_id/len(test_dataloader)*100))+\"%\", end=\"\\r\")\n",
    "        \n",
    "        val_loss_history_classical.append(tracking_val_loss / len(test_dataloader))\n",
    "        \n",
    "        if(best_loss > tracking_val_loss / len(test_dataloader)):\n",
    "            best_loss = tracking_val_loss / len(test_dataloader)\n",
    "            best_classical_model = copy.deepcopy(basic_architecture.state_dict())\n",
    "            torch.save(best_classical_model, \"best_classical_model_resnet50\")\n",
    "    \n",
    "    print(\"Epoch \"+str(epoch))\n",
    "    print(\"\\tloss:\",tracking_loss / len(train_dataloader),\"\\n\\tval_loss:\", tracking_val_loss / len(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting loss performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27080133c48>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss_history_classical) #Noise = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading best model\n",
    "basic_architecture.load_state_dict(torch.load(\"best_classical_model_resnet50\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailing performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = basic_architecture(x_test).detach().numpy()\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "infection_found = 0\n",
    "total_infection = 0\n",
    "ischaemia_found = 0\n",
    "total_ischemia = 0\n",
    "\n",
    "non_ischaemia = 0\n",
    "total_non_ischaemia = 0\n",
    "non_infection = 0\n",
    "total_non_infection = 0\n",
    "\n",
    "for yp, yt in zip(y_pred, y_test):\n",
    "    if(yt[0] == 1):\n",
    "        total_infection += 1\n",
    "        if(yp[0] == 1):\n",
    "            infection_found += 1\n",
    "    else:\n",
    "        total_non_ischaemia += 1\n",
    "        if(yp[0] == 0):\n",
    "            non_ischaemia += 1\n",
    "        \n",
    "    if(yt[1] == 1):\n",
    "        total_ischemia += 1\n",
    "        if(yp[1] == 1):\n",
    "            ischaemia_found += 1\n",
    "    else:\n",
    "        total_non_infection += 1\n",
    "        if(yp[1] == 1):\n",
    "            non_infection += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infection found : 95.88%\n",
      "TN infection found : 75.00%\n",
      "Ischemia found : 96.47%\n",
      "TN ischemia found : 80.00%\n"
     ]
    }
   ],
   "source": [
    "print((\"Infection found : %.2f\" % (infection_found*100/total_infection))+\"%\")\n",
    "print((\"TN infection found : %.2f\" % (non_infection*100/total_non_infection))+\"%\")\n",
    "print((\"Ischemia found : %.2f\" % (ischaemia_found*100/total_ischemia))+\"%\")\n",
    "print((\"TN ischemia found : %.2f\" % (non_ischaemia*100/total_non_ischaemia))+\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
